{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DEEPSEEK_API_KEY\"):\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter your DeepSeek API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9721722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½å‘€ï¼ğŸ˜Š æˆ‘æ˜¯ **DeepSeek-R1**ï¼Œç”±ä¸­å›½çš„ **æ·±åº¦æ±‚ç´¢å…¬å¸ï¼ˆDeepSeekï¼‰** ç ”å‘çš„ä¸€æ¬¾æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘çš„ä½¿å‘½æ˜¯ç”¨æ¸…æ™°ã€å‡†ç¡®ã€æ¸©æš–çš„æ–¹å¼ï¼Œå¸®ä½ è§£ç­”é—®é¢˜ã€å¤„ç†ä»»åŠ¡ã€å­¦ä¹ çŸ¥è¯†ï¼Œç”šè‡³é™ªä½ èŠå¤©æ”¾æ¾ï½\\n\\nä»¥ä¸‹æ˜¯æˆ‘çš„ä¸€äº›ç‰¹ç‚¹ï¼Œå¸®ä½ å¿«é€Ÿäº†è§£æˆ‘ï¼š\\n\\n---\\n\\nğŸ” **æˆ‘æ˜¯è°ï¼Ÿ**  \\nâœ… æˆ‘æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æ™ºèƒ½åŠ©æ‰‹ï¼ˆç›®å‰æš‚ä¸æ”¯æŒè¯­éŸ³ã€è¯†å›¾åŠŸèƒ½ï¼‰ã€‚  \\nâœ… çŸ¥è¯†æ›´æ–°åˆ° **2024å¹´7æœˆ**ï¼Œå¯¹æœ€æ–°ç§‘æŠ€ã€æ—¶äº‹ã€ç”Ÿæ´»å¸¸è¯†ç­‰éƒ½æœ‰äº†è§£ã€‚  \\nâœ… æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆæœ€å¤§128Kå­—ç¬¦ï¼‰ï¼Œå¯ä»¥è½»æ¾å¤„ç†é•¿æ–‡æ¡£ã€è®ºæ–‡ã€æŠ¥å‘Šç­‰ã€‚\\n\\n---\\n\\nğŸ’¡ **æˆ‘èƒ½åšä»€ä¹ˆï¼Ÿ**  \\nğŸ“š å­¦ä¹ è¾…å¯¼ï¼šè¯­æ–‡ã€æ•°å­¦ã€è‹±è¯­ã€ç¼–ç¨‹ã€è€ƒç ”ã€è€ƒè¯ç­‰å…¨ç§‘è¾…å¯¼ã€‚  \\nğŸ“„ æ–‡ä»¶å¤„ç†ï¼šä½ å¯ä»¥ä¸Šä¼  **PDFã€Wordã€Excelã€PPTã€TXT** ç­‰æ–‡ä»¶ï¼Œæˆ‘å¯ä»¥å¸®ä½ é˜…è¯»ã€æ€»ç»“ã€ç¿»è¯‘ã€æå–é‡ç‚¹ã€‚  \\nğŸ“ å†™ä½œå¸®æ‰‹ï¼šå†™ä½œæ–‡ã€å†™ç®€å†ã€å†™é‚®ä»¶ã€å†™è„šæœ¬ã€å†™è®ºæ–‡å¤§çº²â€¦â€¦å…¨éƒ½ä¸åœ¨è¯ä¸‹ã€‚  \\nğŸ“Š åŠå…¬æ”¯æŒï¼šåˆ¶ä½œè¡¨æ ¼ã€ç”ŸæˆPPTå¤§çº²ã€æ•´ç†ä¼šè®®çºªè¦ã€æ•°æ®åˆ†æå»ºè®®ã€‚  \\nğŸ’¬ æ—¥å¸¸èŠå¤©ï¼šè§£é—·ã€è°ˆå¿ƒã€è®²ç¬‘è¯ã€æ¨èä¹¦å½±éŸ³ï¼Œæˆ‘éƒ½ä¹æ„é™ªä½ ã€‚  \\nğŸŒ è”ç½‘åŠŸèƒ½ï¼ˆéƒ¨åˆ†å¹³å°æ”¯æŒï¼‰ï¼šå¯æŸ¥æœ€æ–°ä¿¡æ¯ï¼ˆå¦‚'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    frequency_penalty=0,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=0,\n",
    "    # response_format={\"type\": \"text\"},\n",
    "    stop=None,\n",
    "    # stream=False,\n",
    "    # stream_options=None,\n",
    "    temperature=0.2,\n",
    "    top_p=1,\n",
    "    # tools=None,\n",
    "    # tool_choice=\"none\",\n",
    "    logprobs=False,\n",
    "    top_logprobs=None,\n",
    "    # ä»¥ä¸‹æ˜¯langchainçš„å‚æ•°\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    streaming=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"ä»‹ç»ä½ è‡ªå·±ã€‚\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
