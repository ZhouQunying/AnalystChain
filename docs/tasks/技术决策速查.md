# 技术决策速查

> **快速查询项目技术选型，完整推理过程见历史版本**

---

## 决策总览

### 阶段1：知识库构建

| # | 决策 | 结论 |
|---|------|------|
| #001 | 知识存储 | 向量库+JSON双存储 |
| #002 | 向量库 | Chroma |
| #003 | Embedding | Qwen3-Embedding-0.6B |
| #004 | 知识提取LLM | deepseek-reasoner |
| #005 | Chunk大小 | 800字符 |
| #006 | Chunk重叠 | 100字符 |
| #007 | 检索返回模式 | 完整内容（默认）/预览（可选） |
| #008 | 检索Top-K | 3个结果 |
| #009 | LLM提取参数 | 5页/30000字符 |

### 阶段2：Agent开发

| # | 决策 | 结论 |
|---|------|------|
| #010 | Agent框架 | DeepAgents |
| #011 | Agent LLM | deepseek-chat |

---

## 决策详情

### 阶段1

#### #001：知识存储方式
**结论**：向量库 + JSON双存储
**理由**：向量库做语义检索，JSON做结构化查询，优势互补
**影响**：需LLM提取模块，开发时间+1天

#### #002：向量库选择
**结论**：Chroma
**理由**：LangChain官方推荐，轻量级，本地持久化，API简单
**影响**：本地开发更方便，无云服务依赖

#### #003：Embedding模型
**结论**：Qwen3-Embedding-0.6B
**理由**：中文优化，免费离线，1024维度表达能力强
**影响**：首次下载~600MB，中文检索效果优秀

#### #004：知识提取LLM
**结论**：deepseek-reasoner
**理由**：深度推理能力强，逻辑分析准确，中文能力出色，长文本处理强
**影响**：知识提取质量高，分析深度好

#### #005：Chunk大小配置
**结论**：800字符
**理由**：平衡完整性与精度，约1个完整段落，过小碎片化，过大稀释相关性
**影响**：宏观经济文档平均1400字/页，800字约半页，检索精度提升

#### #006：Chunk重叠配置
**结论**：100字符（12.5%重叠）
**理由**：保证上下文连续性，避免关键信息被切断在chunk边界
**影响**：略增存储量（12.5%），显著提升检索连贯性

#### #007：检索返回模式
**结论**：默认完整内容，可选150字符预览
**理由**：Agent需完整信息回答问题，担心token应减少k值而非截断内容
**影响**：`vector_search(preview_only=True)`启用预览模式

#### #008：检索结果数量
**结论**：Top-3
**理由**：多结果综合提高覆盖率，3个平衡信息量与token消耗
**影响**：3×150字≈450 tokens，在上下文预算内

#### #009：LLM提取参数配置
**结论**：每批5页/30000字符
**计算过程**：
```
约束条件：
- deepseek-reasoner 上下文限制：64k tokens
- 中文 token 比例：1字符 ≈ 1.5 tokens
- 安全边际：80%（留空间给 prompt + 输出）

计算：
可用 tokens = 64000 × 80% = 51200 tokens
可用字符 = 51200 / 1.5 ≈ 34000 字符
取整：30000 字符
```
**调整指南**：
- 如果单批经常超限 → 减小 EXTRACT_MAX_PAGES
- 如果需要更多信息 → 可小幅增加到 35000 字符
- 如果切换 LLM → 按新模型 token 限制重新计算
**影响**：每批处理量减少，批次数增加，但信息丢失风险降低

### 阶段2

#### #010：Agent框架
**结论**：DeepAgents
**理由**：LangChain官方新框架，内置Planning/FileSystem/SubAgent，适合投资分析
**影响**：Agent开发效率提升，内存管理简单

#### #011：Agent LLM模型
**结论**：deepseek-chat
**理由**：支持工具调用+流式输出，成本低（¥1/M），响应稳定，中文能力强
**影响**：Agent开发成本低，响应质量高

---

## 完整推理过程

如需查看完整的背景/候选方案/对比分析，请查看：
- 历史版本：`docs/tasks/技术决策.md`（已归档到_archive/）
- 或询问AI重新生成

---

**此文档只保留结论，避免重复阅读。**
