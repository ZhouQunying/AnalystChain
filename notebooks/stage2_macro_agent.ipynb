{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1497ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[å®Œæˆ] å·¥å…·å‡½æ•°åŠ è½½å®Œæˆ (æ—¥å¿—çº§åˆ«: WARNING)\n"
     ]
    }
   ],
   "source": [
    "# ========== AKShareå·¥å…·å‡½æ•° ==========\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "# é…ç½®æ—¥å¿— - ä½¿ç”¨WARNINGçº§åˆ«é¿å…åˆ·å±\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# å¼ºåˆ¶å…³é—­å¹²æ‰°æ—¥å¿—ï¼ˆç¡®ä¿æµå¼è¾“å‡ºçº¯å‡€ï¼‰\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"chromadb\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"akshare\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"src.analyst_chain.tools.akshare_tools\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "def get_gdp_quarterly() -> str:\n",
    "    \"\"\"è·å–å­£åº¦GDPæ•°æ®\n",
    "\n",
    "    Returns:\n",
    "        æ ¼å¼åŒ–çš„GDPæ•°æ®å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    print(\"[å·¥å…·] è·å–GDPæ•°æ®...\", end=\"\", flush=True)\n",
    "    try:\n",
    "        df = ak.macro_china_gdp()\n",
    "        if df.empty:\n",
    "            print(\" å¤±è´¥\")\n",
    "            return \"è·å–GDPæ•°æ®å¤±è´¥ï¼šæ•°æ®ä¸ºç©º\"\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'å­£åº¦': 'quarter',\n",
    "            'å›½å†…ç”Ÿäº§æ€»å€¼-ç»å¯¹å€¼': 'gdp',\n",
    "            'å›½å†…ç”Ÿäº§æ€»å€¼-åŒæ¯”å¢é•¿': 'gdp_yoy'\n",
    "        })\n",
    "        df = df[['quarter', 'gdp', 'gdp_yoy']]\n",
    "        df['gdp'] = pd.to_numeric(df['gdp'], errors='coerce')\n",
    "        df['gdp_yoy'] = pd.to_numeric(df['gdp_yoy'], errors='coerce')\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        result = \"GDPå­£åº¦æ•°æ®(æœ€è¿‘5ä¸ªå­£åº¦):\\n\\n\"\n",
    "        for _, row in df.head(5).iterrows():\n",
    "            result += f\"å­£åº¦: {row['quarter']}, GDP: {row['gdp']}äº¿å…ƒ, åŒæ¯”å¢é•¿: {row['gdp_yoy']}%\\n\"\n",
    "\n",
    "        print(\" å®Œæˆ\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\" å¤±è´¥: {e}\")\n",
    "        return f\"è·å–GDPæ•°æ®å¤±è´¥: {str(e)}\"\n",
    "\n",
    "\n",
    "def get_cpi_monthly() -> str:\n",
    "    \"\"\"è·å–æœˆåº¦CPIæ•°æ®\n",
    "\n",
    "    Returns:\n",
    "        æ ¼å¼åŒ–çš„CPIæ•°æ®å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    print(\"[å·¥å…·] è·å–CPIæ•°æ®...\", end=\"\", flush=True)\n",
    "    try:\n",
    "        df = ak.macro_china_cpi()\n",
    "        if df.empty:\n",
    "            print(\" å¤±è´¥\")\n",
    "            return \"è·å–CPIæ•°æ®å¤±è´¥ï¼šæ•°æ®ä¸ºç©º\"\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'æœˆä»½': 'month',\n",
    "            'å…¨å›½-åŒæ¯”å¢é•¿': 'cpi_yoy',\n",
    "            'å…¨å›½-ç¯æ¯”å¢é•¿': 'cpi_mom',\n",
    "            'å…¨å›½-ç´¯è®¡': 'cpi_ytd'\n",
    "        })\n",
    "        df = df[['month', 'cpi_yoy', 'cpi_mom', 'cpi_ytd']]\n",
    "        df['cpi_yoy'] = pd.to_numeric(df['cpi_yoy'], errors='coerce')\n",
    "        df['cpi_mom'] = pd.to_numeric(df['cpi_mom'], errors='coerce')\n",
    "        df['cpi_ytd'] = pd.to_numeric(df['cpi_ytd'], errors='coerce')\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        result = \"CPIæœˆåº¦æ•°æ®(æœ€è¿‘6ä¸ªæœˆ):\\n\\n\"\n",
    "        for _, row in df.head(6).iterrows():\n",
    "            result += f\"æœˆä»½: {row['month']}, åŒæ¯”: {row['cpi_yoy']}%, ç¯æ¯”: {row['cpi_mom']}%, ç´¯è®¡: {row['cpi_ytd']}%\\n\"\n",
    "\n",
    "        print(\" å®Œæˆ\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\" å¤±è´¥: {e}\")\n",
    "        return f\"è·å–CPIæ•°æ®å¤±è´¥: {str(e)}\"\n",
    "\n",
    "\n",
    "def get_pmi_manufacturing() -> str:\n",
    "    \"\"\"è·å–åˆ¶é€ ä¸šPMIæ•°æ®\n",
    "\n",
    "    Returns:\n",
    "        æ ¼å¼åŒ–çš„PMIæ•°æ®å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    print(\"[å·¥å…·] è·å–PMIæ•°æ®...\", end=\"\", flush=True)\n",
    "    try:\n",
    "        df = ak.macro_china_pmi()\n",
    "        if df.empty:\n",
    "            print(\" å¤±è´¥\")\n",
    "            return \"è·å–PMIæ•°æ®å¤±è´¥ï¼šæ•°æ®ä¸ºç©º\"\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'æœˆä»½': 'month',\n",
    "            'åˆ¶é€ ä¸š-æŒ‡æ•°': 'pmi',\n",
    "            'åˆ¶é€ ä¸š-åŒæ¯”å¢é•¿': 'pmi_yoy'\n",
    "        })\n",
    "        df = df[['month', 'pmi', 'pmi_yoy']]\n",
    "        df['pmi'] = pd.to_numeric(df['pmi'], errors='coerce')\n",
    "        df['pmi_yoy'] = pd.to_numeric(df['pmi_yoy'], errors='coerce')\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        result = \"PMIåˆ¶é€ ä¸šæ•°æ®(æœ€è¿‘6ä¸ªæœˆ):\\n\\n\"\n",
    "        for _, row in df.head(6).iterrows():\n",
    "            result += f\"æœˆä»½: {row['month']}, PMIæŒ‡æ•°: {row['pmi']}, åŒæ¯”å¢é•¿: {row['pmi_yoy']}%\\n\"\n",
    "\n",
    "        print(\" å®Œæˆ\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\" å¤±è´¥: {e}\")\n",
    "        return f\"è·å–PMIæ•°æ®å¤±è´¥: {str(e)}\"\n",
    "\n",
    "\n",
    "# ========== çŸ¥è¯†åº“æ£€ç´¢å·¥å…· ==========\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "class KnowledgeRetriever:\n",
    "    \"\"\"çŸ¥è¯†åº“æ£€ç´¢å·¥å…·\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vector_db_path: str = \"../data/processed/knowledge/vector_db/knowledge_base\",\n",
    "                 json_dir_path: str = \"../data/processed/knowledge/structured/knowledge_base\",\n",
    "                 embedding_model: Optional[str] = None):\n",
    "        \"\"\"åˆå§‹åŒ–çŸ¥è¯†åº“æ£€ç´¢å™¨\"\"\"\n",
    "        self.vector_db_path = Path(vector_db_path)\n",
    "        self.json_dir_path = Path(json_dir_path)\n",
    "\n",
    "        if embedding_model is None:\n",
    "            import os\n",
    "            embedding_model = os.getenv('EMBEDDING_MODEL_PATH', 'Qwen/Qwen3-Embedding-0.6B')\n",
    "\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.vector_store = Chroma(\n",
    "            collection_name=\"knowledge_base_col\",\n",
    "            persist_directory=str(self.vector_db_path),\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "\n",
    "        self._load_json_index()\n",
    "\n",
    "    def _load_json_index(self):\n",
    "        \"\"\"åŠ è½½JSONæ–‡ä»¶ç´¢å¼•\"\"\"\n",
    "        self.json_files = {}\n",
    "        for json_file in self.json_dir_path.glob(\"*.json\"):\n",
    "            topic_num = int(json_file.name.split(\"_\")[0])\n",
    "            self.json_files[topic_num] = json_file\n",
    "\n",
    "    def vector_search(self, query: str, k: int = 3) -> str:\n",
    "        \"\"\"å‘é‡æ£€ç´¢\"\"\"\n",
    "        results = self.vector_store.similarity_search(query, k=k)\n",
    "\n",
    "        if not results:\n",
    "            return \"æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†\"\n",
    "\n",
    "        output = f\"å‘é‡æ£€ç´¢ç»“æœ(å…±{len(results)}æ¡):\\n\\n\"\n",
    "        for i, doc in enumerate(results, 1):\n",
    "            output += f\"[ç»“æœ{i}]\\n\"\n",
    "            output += f\"å†…å®¹: {doc.page_content[:200]}...\\n\"\n",
    "            if doc.metadata:\n",
    "                output += f\"æ¥æº: ä¸»é¢˜{doc.metadata.get('seq', 'N/A')} - {doc.metadata.get('topic', 'N/A')}\\n\"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_topic_knowledge(self, topic_number: int) -> str:\n",
    "        \"\"\"æŒ‰ä¸»é¢˜æŸ¥è¯¢JSONçŸ¥è¯†\"\"\"\n",
    "        if topic_number not in self.json_files:\n",
    "            return f\"é”™è¯¯: ä¸»é¢˜{topic_number}ä¸å­˜åœ¨(æœ‰æ•ˆèŒƒå›´1-17)\"\n",
    "\n",
    "        json_file = self.json_files[topic_number]\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            knowledge = json.load(f)\n",
    "\n",
    "        output = f\"ä¸»é¢˜{topic_number}: {knowledge.get('topic', 'N/A')}\\n\\n\"\n",
    "\n",
    "        if 'key_concepts' in knowledge:\n",
    "            output += \"å…³é”®æ¦‚å¿µ:\\n\"\n",
    "            for concept in knowledge['key_concepts'][:5]:\n",
    "                name = concept.get('name', 'N/A')\n",
    "                definition = concept.get('definition', 'N/A')\n",
    "                output += f\"  - {name}: {definition}\\n\"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        if 'indicators' in knowledge:\n",
    "            output += \"å…³é”®æŒ‡æ ‡:\\n\"\n",
    "            for indicator in knowledge['indicators'][:3]:\n",
    "                name = indicator.get('name', 'N/A')\n",
    "                description = indicator.get('description', 'N/A')\n",
    "                output += f\"  - {name}: {description}\\n\"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        if 'summary' in knowledge:\n",
    "            output += f\"æ‘˜è¦:\\n{knowledge['summary'][:300]}...\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "print(\"[å®Œæˆ] å·¥å…·å‡½æ•°åŠ è½½å®Œæˆ (æ—¥å¿—çº§åˆ«: WARNING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51178c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åˆå§‹åŒ–] 1/4 åŠ è½½ç¯å¢ƒå˜é‡...\n",
      "[åˆå§‹åŒ–] 2/4 åˆ›å»ºçŸ¥è¯†æ£€ç´¢å™¨...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åˆå§‹åŒ–] 3/4 åŒ…è£…çŸ¥è¯†æ£€ç´¢å·¥å…·...\n",
      "[åˆå§‹åŒ–] 4/4 åˆ›å»ºDeepAgent+SubAgent...\n",
      "[æˆåŠŸ] DeepAgent+SubAgentæ¶æ„å·²åˆ›å»º\n",
      "   ç±»å‹: CompiledStateGraph\n",
      "   æ¨¡å‹: DeepSeek (deepseek-chat)\n",
      "   SubAgent: macroeconomic_subagent\n",
      "   å·¥å…·æ•°é‡: 5ä¸ª\n",
      "     - AKShareå·¥å…·: 3ä¸ª (GDP/CPI/PMI)\n",
      "     - çŸ¥è¯†æ£€ç´¢: 2ä¸ª (å‘é‡æ£€ç´¢/JSONæŸ¥è¯¢)\n",
      "\n",
      "[æç¤º] Tokençº§æµå¼è¾“å‡ºå·²å¯ç”¨ï¼Œå¸¦è¯¦ç»†è¿›åº¦è¿½è¸ª\n"
     ]
    }
   ],
   "source": [
    "# é˜¶æ®µ2ï¼šå®è§‚ç»æµSubAgentå®ç°ï¼ˆDeepAgentæ¶æ„ï¼‰\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../config/.env')\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from deepagents import create_deep_agent\n",
    "\n",
    "print(\"[åˆå§‹åŒ–] 1/4 åŠ è½½ç¯å¢ƒå˜é‡...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# åˆå§‹åŒ–DeepSeekæ¨¡å‹\n",
    "deepseek_model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    openai_api_base=\"https://api.deepseek.com\",\n",
    "    streaming=True,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(\"[åˆå§‹åŒ–] 2/4 åˆ›å»ºçŸ¥è¯†æ£€ç´¢å™¨...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢å™¨\n",
    "knowledge_retriever = KnowledgeRetriever()\n",
    "\n",
    "print(\"[åˆå§‹åŒ–] 3/4 åŒ…è£…çŸ¥è¯†æ£€ç´¢å·¥å…·...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# åŒ…è£…çŸ¥è¯†æ£€ç´¢æ–¹æ³•ä¸ºç‹¬ç«‹å‡½æ•°\n",
    "def vector_search(query: str, k: int = 3) -> str:\n",
    "    \"\"\"å‘é‡æ£€ç´¢çŸ¥è¯†åº“\n",
    "\n",
    "    Args:\n",
    "        query: æŸ¥è¯¢æ–‡æœ¬\n",
    "        k: è¿”å›ç»“æœæ•°é‡(é»˜è®¤3)\n",
    "\n",
    "    Returns:\n",
    "        æ£€ç´¢ç»“æœæ–‡æœ¬\n",
    "    \"\"\"\n",
    "    print(\"[å·¥å…·] å‘é‡æ£€ç´¢...\", end=\"\", flush=True)\n",
    "    result = knowledge_retriever.vector_search(query, k)\n",
    "    print(\" å®Œæˆ\")\n",
    "    return result\n",
    "\n",
    "def get_topic_knowledge(topic_number: int) -> str:\n",
    "    \"\"\"æŒ‰ä¸»é¢˜ç¼–å·æŸ¥è¯¢JSONçŸ¥è¯†\n",
    "\n",
    "    Args:\n",
    "        topic_number: ä¸»é¢˜ç¼–å·(1-17)\n",
    "\n",
    "    Returns:\n",
    "        ä¸»é¢˜çŸ¥è¯†å†…å®¹\n",
    "    \"\"\"\n",
    "    print(f\"[å·¥å…·] æŸ¥è¯¢ä¸»é¢˜{topic_number}...\", end=\"\", flush=True)\n",
    "    result = knowledge_retriever.get_topic_knowledge(topic_number)\n",
    "    print(\" å®Œæˆ\")\n",
    "    return result\n",
    "\n",
    "print(\"[åˆå§‹åŒ–] 4/4 åˆ›å»ºDeepAgent+SubAgent...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# å®šä¹‰å®è§‚ç»æµSubAgenté…ç½®ï¼ˆå­—å…¸æ ¼å¼ï¼‰\n",
    "macroeconomic_subagent = {\n",
    "    \"name\": \"macroeconomic_subagent\",\n",
    "    \"description\": \"è´Ÿè´£å®è§‚ç»æµåˆ†æ,åŒ…æ‹¬GDPã€CPIã€PMIç­‰æŒ‡æ ‡çš„æ•°æ®è·å–ã€åˆ†æå’Œè¶‹åŠ¿åˆ¤æ–­ã€‚ç»“åˆå®æ—¶æ•°æ®å’Œç†è®ºçŸ¥è¯†æä¾›ä¸“ä¸šåˆ†æã€‚\",\n",
    "    \"system_prompt\": \"\"\"ä½ æ˜¯å®è§‚ç»æµåˆ†æä¸“å®¶ã€‚\n",
    "\n",
    "æ ¸å¿ƒèƒ½åŠ›ï¼š\n",
    "1. æ•°æ®è·å–ï¼šä½¿ç”¨AKShareå·¥å…·è·å–æœ€æ–°å®è§‚ç»æµæ•°æ®(GDPã€CPIã€PMIç­‰)\n",
    "2. ç†è®ºæ”¯æ’‘ï¼šæŸ¥è¯¢çŸ¥è¯†åº“è·å–ç›¸å…³ç»æµç†è®ºå’Œåˆ†ææ¡†æ¶\n",
    "3. ç»¼åˆåˆ†æï¼šç»“åˆå®æ—¶æ•°æ®å’Œç†è®ºçŸ¥è¯†ï¼Œæä¾›ä¸“ä¸šçš„ç»æµè§£è¯»\n",
    "\n",
    "åˆ†ææµç¨‹ï¼š\n",
    "1. è·å–ç›¸å…³æ•°æ®ï¼ˆä½¿ç”¨get_gdp_quarterly/get_cpi_monthly/get_pmi_manufacturingï¼‰\n",
    "2. æŸ¥è¯¢ç†è®ºæ¡†æ¶ï¼ˆä½¿ç”¨vector_searchï¼‰\n",
    "3. åˆ†ææ•°æ®è¶‹åŠ¿å’Œå‘¨æœŸç‰¹å¾\n",
    "4. ç»™å‡ºä¸“ä¸šåˆ¤æ–­å’Œé¢„æµ‹\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- æ•°æ®å‡†ç¡®ï¼Œå¼•ç”¨æ¥æºï¼ˆå¦‚\"æ ¹æ®AKShareæœ€æ–°æ•°æ®...\"ï¼‰\n",
    "- åˆ†æä¸“ä¸šï¼Œè¿ç”¨ç†è®ºï¼ˆå¦‚\"æ ¹æ®ç»æµå‘¨æœŸç†è®º...\"ï¼‰\n",
    "- é€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´ï¼ˆæ•°æ®â†’ç†è®ºâ†’åˆ†æâ†’ç»“è®ºï¼‰\n",
    "- ç»“è®ºæ˜ç¡®ï¼Œä¾¿äºç†è§£\"\"\",\n",
    "    \"tools\": [\n",
    "        get_gdp_quarterly,\n",
    "        get_cpi_monthly,\n",
    "        get_pmi_manufacturing,\n",
    "        vector_search,\n",
    "        get_topic_knowledge,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# åˆ›å»ºMain Agentï¼ˆä½¿ç”¨create_deep_agentï¼‰\n",
    "main_agent = create_deep_agent(\n",
    "    model=deepseek_model,\n",
    "    subagents=[macroeconomic_subagent],\n",
    ")\n",
    "\n",
    "print(\"[æˆåŠŸ] DeepAgent+SubAgentæ¶æ„å·²åˆ›å»º\")\n",
    "print(f\"   ç±»å‹: {type(main_agent).__name__}\")\n",
    "print(f\"   æ¨¡å‹: DeepSeek (deepseek-chat)\")\n",
    "print(f\"   SubAgent: macroeconomic_subagent\")\n",
    "print(f\"   å·¥å…·æ•°é‡: 5ä¸ª\")\n",
    "print(f\"     - AKShareå·¥å…·: 3ä¸ª (GDP/CPI/PMI)\")\n",
    "print(f\"     - çŸ¥è¯†æ£€ç´¢: 2ä¸ª (å‘é‡æ£€ç´¢/JSONæŸ¥è¯¢)\")\n",
    "print(\"\\n[æç¤º] Tokençº§æµå¼è¾“å‡ºå·²å¯ç”¨ï¼Œå¸¦è¯¦ç»†è¿›åº¦è¿½è¸ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54073a58",
   "metadata": {},
   "source": [
    "## é˜¶æ®µ2ä»»åŠ¡è¿›åº¦\n",
    "\n",
    "**æ€»è¿›åº¦**: 3/3ä»»åŠ¡ (100%) âœ…\n",
    "\n",
    "| ä»»åŠ¡ | çŠ¶æ€ | è¯´æ˜ |\n",
    "|------|------|------|\n",
    "| 1. æ ¸å¿ƒToolså°è£… | âœ… å®Œæˆ | çŸ¥è¯†åº“æ£€ç´¢(2ä¸ª) + AKShare(3ä¸ªGDP/CPI/PMI) |\n",
    "| 2. Main+SubAgentå®ç° | âœ… å®Œæˆ | DeepAgentæ¶æ„ï¼Œ1ä¸ªå®è§‚ç»æµSubAgent |\n",
    "| 3. æµ‹è¯•ä¸éªŒè¯ | ğŸ”„ è¿›è¡Œä¸­ | æœ¬notebookæ­£åœ¨éªŒè¯DeepAgentæ¶æ„æ€§èƒ½ |\n",
    "\n",
    "**å½“å‰ä»»åŠ¡**: æµ‹è¯•3 - éªŒè¯DeepAgent+SubAgentæ¶æ„çš„æ‰§è¡Œæµç¨‹å’Œæ€§èƒ½\n",
    "\n",
    "**æµ‹è¯•ç›®æ ‡**:\n",
    "- éªŒè¯Main Agent â†’ SubAgentçš„è°ƒç”¨æµç¨‹\n",
    "- è¿½è¸ª180ç§’å»¶è¿Ÿçš„è¯¦ç»†è¿‡ç¨‹\n",
    "- ç¡®è®¤å·¥å…·è°ƒç”¨å’ŒçŸ¥è¯†æ£€ç´¢çš„æ­£ç¡®æ€§\n",
    "\n",
    "---\n",
    "\n",
    "## æµ‹è¯•åœºæ™¯\n",
    "\n",
    "æµ‹è¯•å®è§‚ç»æµSubAgentçš„ç»¼åˆåˆ†æèƒ½åŠ›ï¼ˆDeepAgentæ¶æ„ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b265df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[æ€»è¿›åº¦] æµ‹è¯•1/3: GDPåˆ†æ (DeepAgent+SubAgentæ¶æ„)\n",
      "================================================================================\n",
      "é—®é¢˜ï¼šæœ€è¿‘GDPå¢é•¿ç‡å¦‚ä½•ï¼Ÿæœ‰ä»€ä¹ˆè¶‹åŠ¿ç‰¹å¾ï¼Ÿ\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[10:55:23] å¼€å§‹æ‰§è¡Œ\n",
      "[è¿›åº¦] 1/6 å‘é€é—®é¢˜åˆ°Main Agent...\n",
      "[è¿›åº¦] 2/6 Main Agentå†³ç­–ä¸­ï¼ˆåˆ†æé—®é¢˜ï¼Œé€‰æ‹©SubAgentï¼‰...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10:55:25] [è¿›åº¦] 5/6 SubAgentè¿”å›ç»“æœ (æ€»å»¶è¿Ÿ1.8s)\n",
      "[è¿›åº¦] 6/6 æµå¼è¾“å‡ºä¸­...\n",
      "\n",
      "å›ç­”ï¼šæˆ‘æ¥ä¸ºæ‚¨åˆ†ææœ€è¿‘çš„GDPå¢é•¿ç‡å’Œè¶‹åŠ¿ç‰¹å¾ã€‚è®©æˆ‘ä½¿ç”¨å®è§‚ç»æµåˆ†æå­ä»£ç†æ¥è·å–æœ€æ–°çš„æ•°æ®å’Œä¸“ä¸šåˆ†æã€‚[å·¥å…·] è·å–GDPæ•°æ®... å®Œæˆ\n",
      "[å·¥å…·] å‘é‡æ£€ç´¢... å®Œæˆ\n",
      "[å·¥å…·] å‘é‡æ£€ç´¢... å®Œæˆ\n",
      "[å·¥å…·] å‘é‡æ£€ç´¢... å®Œæˆ\n",
      "[å·¥å…·] æŸ¥è¯¢ä¸»é¢˜1... å®Œæˆ\n",
      "[å·¥å…·] è·å–CPIæ•°æ®... å®Œæˆ\n",
      "[å·¥å…·] è·å–PMIæ•°æ®... å®Œæˆ\n",
      "\n",
      "[10:57:56] [è¿›åº¦] 3/6 Main Agentå·²å†³ç­–ï¼Œè°ƒç”¨SubAgent (è€—æ—¶152.1s)\n",
      "[è¿›åº¦] 4/6 SubAgentæ‰§è¡Œä¸­ï¼ˆè°ƒç”¨å·¥å…·+åˆ†æï¼‰...\n",
      "\n",
      "[10:57:56] å·¥å…·è°ƒç”¨ 1 å®Œæˆ (è€—æ—¶152.1s)\n",
      "æ ¹æ®å®è§‚ç»æµåˆ†æå­ä»£ç†çš„ä¸“ä¸šåˆ†æï¼Œä»¥ä¸‹æ˜¯å…³äºæœ€è¿‘GDPå¢é•¿ç‡å’Œè¶‹åŠ¿ç‰¹å¾çš„è¯¦ç»†æ€»ç»“ï¼š\n",
      "\n",
      "## ğŸ“Š **æœ€æ–°GDPå¢é•¿ç‡æ•°æ®**\n",
      "\n",
      "### **è¿‘æœŸè¡¨ç°**\n",
      "- **2025å¹´å‰ä¸‰å­£åº¦**ï¼šGDPå¢é•¿**5.2%**ï¼Œé«˜äº2024å¹´åŒæœŸçš„4.8%\n",
      "- **å­£åº¦èŠ‚å¥**ï¼šå‘ˆç°\"å‰é«˜åç¨³\"ç‰¹å¾\n",
      "  - 2025å¹´ä¸€å­£åº¦ï¼š5.4%\n",
      "  - 2025å¹´äºŒã€ä¸‰å­£åº¦ï¼šç¨³å®šåœ¨5.2-5.3%åŒºé—´\n",
      "- **2024å¹´å…¨å¹´**ï¼šå¢é•¿**5.0%**\n",
      "- **2025å¹´é¢„æœŸ**ï¼šæœ‰æœ›å®ç°5.1-5.3%çš„å¢é•¿\n",
      "\n",
      "## ğŸ“ˆ **ä¸»è¦è¶‹åŠ¿ç‰¹å¾**\n",
      "\n",
      "### **1. æ¸©å’Œå¤è‹æ€åŠ¿**\n",
      "- ç»æµä»2024å¹´çš„4.8%å¢é•¿å›å‡è‡³2025å¹´çš„5.2%\n",
      "- æ˜¾ç¤ºç»æµæ­£åœ¨æ¸©å’Œå¤è‹ï¼Œä½†å¢é€Ÿç›¸å¯¹å¹³ç¨³\n",
      "\n",
      "### **2. å¢é•¿ç»“æ„è½¬å‹**\n",
      "- **æ¶ˆè´¹ä¸»å¯¼å‹ç‰¹å¾æ˜æ˜¾**ï¼šæ¶ˆè´¹å æ¯”çº¦53%ï¼Œæˆä¸ºç»æµå¢é•¿çš„ä¸»è¦é©±åŠ¨åŠ›\n",
      "- **æŠ•èµ„æ”¯æ’‘ä½œç”¨**ï¼šæŠ•èµ„å æ¯”çº¦44%ï¼Œç»§ç»­å‘æŒ¥é‡è¦æ”¯æ’‘ä½œç”¨\n",
      "- **å‡€å‡ºå£è´¡çŒ®æœ‰é™**ï¼šä»…å çº¦3%\n",
      "\n",
      "### **3. ç»æµå‘¨æœŸä½ç½®**\n",
      "å½“å‰ä¸­å›½ç»æµå¤„äº**å¤è‹é˜¶æ®µå‘ç¨³å®šå¢é•¿è¿‡æ¸¡æœŸ**ï¼Œè¡¨ç°ä¸ºï¼š\n",
      "- âœ… **äº§å‡ºå¢é•¿ç¨³å®š**ï¼šGDPå¢é•¿ç‡ä¿æŒåœ¨5%ä»¥ä¸Š\n",
      "- âš ï¸ **é€šèƒ€å‹åŠ›æ¸©å’Œ**ï¼šCPIåœ¨0-1%åŒºé—´ï¼Œæ˜¾ç¤ºéœ€æ±‚ç›¸å¯¹å¹³ç¨³\n",
      "- âš ï¸ **åˆ¶é€ ä¸šä»åœ¨è°ƒæ•´**ï¼šPMIç•¥ä½äºè£æ¯çº¿ï¼Œåˆ¶é€ ä¸šé¢ä¸´ä¸€å®šå‹åŠ›\n",
      "\n",
      "## ğŸ” **å…³é”®å½±å“å› ç´ **\n",
      "\n",
      "### **ç§¯æå› ç´ **\n",
      "1. **æ¶ˆè´¹æŒç»­æ¢å¤**ï¼šå†…éœ€å¸‚åœºé€æ­¥å›æš–\n",
      "2. **æ”¿ç­–æ”¯æŒ**ï¼šç¨³å¢é•¿æ”¿ç­–æŒç»­å‘åŠ›\n",
      "3. **äº§ä¸šå‡çº§**ï¼šé«˜æŠ€æœ¯äº§ä¸šä¿æŒè¾ƒå¿«å¢é•¿\n",
      "\n",
      "### **æŒ‘æˆ˜å› ç´ **\n",
      "1. **å¤–éƒ¨ç¯å¢ƒ**ï¼šé€†å…¨çƒåŒ–ã€æŠ€æœ¯ç«äº‰ç­‰å›½é™…æŒ‘æˆ˜\n",
      "2. **å†…éƒ¨ç»“æ„**ï¼šäººå£ç»“æ„å˜åŒ–ã€æˆ¿åœ°äº§è°ƒæ•´ç­‰å‹åŠ›\n",
      "3. **åˆ¶é€ ä¸šè°ƒæ•´**ï¼šPMIæ•°æ®æ˜¾ç¤ºåˆ¶é€ ä¸šä»åœ¨é€‚åº”æœŸ\n",
      "\n",
      "## ğŸŒ **å›½é™…æ¯”è¾ƒ**\n",
      "- åœ¨å…¨çƒä¸»è¦ç»æµä½“ä¸­ï¼Œä¸­å›½ä»ä¿æŒ**ç›¸å¯¹è¾ƒé«˜çš„å¢é•¿æ°´å¹³**\n",
      "- ä½†å¢é€Ÿå·²ä»è¿‡å»çš„é«˜é€Ÿå¢é•¿è½¬å‘**ä¸­é«˜é€Ÿå¢é•¿é˜¶æ®µ**\n",
      "\n",
      "## ğŸ”® **è¶‹åŠ¿å±•æœ›**\n",
      "\n",
      "### **çŸ­æœŸï¼ˆ2025-2026å¹´ï¼‰**\n",
      "- é¢„è®¡ä¿æŒ**5%å·¦å³çš„å¢é•¿æ°´å¹³**\n",
      "- ç»æµå°†ç»§ç»­æ¸©å’Œå¤è‹\n",
      "\n",
      "### **ä¸­é•¿æœŸè½¬å‹**\n",
      "ä¸­å›½ç»æµæ­£åœ¨ç»å†\"ä¸‰å¤§è½¬å‹\"ï¼š\n",
      "1. **å¢é€Ÿè½¬å‹**ï¼šä»é«˜é€Ÿå¢é•¿å‘ä¸­é«˜é€Ÿå¢é•¿\n",
      "2. **åŠ¨åŠ›è½¬å‹**ï¼šä»è¦ç´ é©±åŠ¨å‘åˆ›æ–°é©±åŠ¨\n",
      "3. **ç»“æ„è½¬å‹**ï¼šä»æŠ•èµ„å‡ºå£ä¸»å¯¼å‘æ¶ˆè´¹ä¸»å¯¼\n",
      "\n",
      "## ğŸ’¡ **æ ¸å¿ƒç»“è®º**\n",
      "\n",
      "**å½“å‰ä¸­å›½GDPå¢é•¿å‘ˆç°\"æ¸©å’Œå¤è‹ã€ç»“æ„ä¼˜åŒ–ã€å¢é€Ÿå¹³ç¨³\"çš„ç‰¹å¾**ï¼š\n",
      "- âœ… å¢é•¿ç‡ç¨³å®šåœ¨5%ä»¥ä¸Šï¼Œæ˜¾ç¤ºç»æµåŸºæœ¬é¢ç¨³å¥\n",
      "- âœ… æ¶ˆè´¹æˆä¸ºä¸»è¦é©±åŠ¨åŠ›ï¼Œå¢é•¿ç»“æ„æ›´åŠ å¥åº·\n",
      "- âš ï¸ é¢ä¸´å†…å¤–å¤šé‡æŒ‘æˆ˜ï¼Œéœ€è¦æŒç»­çš„æ”¿ç­–æ”¯æŒå’Œç»“æ„è°ƒæ•´\n",
      "- ğŸ“Š é¢„è®¡æœªæ¥å°†ä¿æŒä¸­é«˜é€Ÿå¢é•¿ï¼Œå®Œæˆé«˜è´¨é‡å‘å±•è½¬å‹\n",
      "\n",
      "è¿™ä¸ªåˆ†æåŸºäºæœ€æ–°çš„å®é™…æ•°æ®å’Œç»æµç†è®ºæ¡†æ¶ï¼Œåæ˜ äº†å½“å‰ä¸­å›½ç»æµçš„çœŸå®çŠ¶å†µå’Œå‘å±•è¶‹åŠ¿ã€‚\n",
      "\n",
      "[10:58:19] [å®Œæˆ]\n",
      "--------------------------------------------------------------------------------\n",
      "[ç»Ÿè®¡] æ€»è€—æ—¶: 175.57s | å·¥å…·è°ƒç”¨: 1æ¬¡ | é¦–tokenå»¶è¿Ÿ: 1.8s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•1ï¼šGDPåˆ†æï¼ˆDeepAgentè¯¦ç»†è¿›åº¦è¿½è¸ªï¼‰\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessageChunk, ToolMessage\n",
    "\n",
    "test_query_1 = \"æœ€è¿‘GDPå¢é•¿ç‡å¦‚ä½•ï¼Ÿæœ‰ä»€ä¹ˆè¶‹åŠ¿ç‰¹å¾ï¼Ÿ\"\n",
    "\n",
    "# è¿›åº¦è¿½è¸ª\n",
    "print(\"=\" * 80)\n",
    "print(f\"[æ€»è¿›åº¦] æµ‹è¯•1/3: GDPåˆ†æ (DeepAgent+SubAgentæ¶æ„)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"é—®é¢˜ï¼š{test_query_1}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ‰§è¡Œ\")\n",
    "print(\"[è¿›åº¦] 1/6 å‘é€é—®é¢˜åˆ°Main Agent...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# çŠ¶æ€è¿½è¸ª\n",
    "stage_times = {}\n",
    "tool_call_count = 0\n",
    "output_started = False\n",
    "first_token_time = None\n",
    "subagent_started = False\n",
    "\n",
    "print(\"[è¿›åº¦] 2/6 Main Agentå†³ç­–ä¸­ï¼ˆåˆ†æé—®é¢˜ï¼Œé€‰æ‹©SubAgentï¼‰...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# è®°å½•Main Agentå†³ç­–æ—¶é—´\n",
    "stage_times['main_agent_start'] = time.time()\n",
    "\n",
    "# LangGraphçš„streamæ–¹æ³•ï¼ˆå­—å…¸è¾“å…¥ + stream_mode=\"messages\"ï¼‰\n",
    "response_text = \"\"\n",
    "for message_chunk, metadata in main_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": test_query_1}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # æ£€æµ‹å·¥å…·è°ƒç”¨ï¼ˆSubAgentæ‰§è¡Œï¼‰\n",
    "    if isinstance(message_chunk, ToolMessage):\n",
    "        if not subagent_started:\n",
    "            elapsed = current_time - start_time\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] [è¿›åº¦] 3/6 Main Agentå·²å†³ç­–ï¼Œè°ƒç”¨SubAgent (è€—æ—¶{elapsed:.1f}s)\")\n",
    "            print(\"[è¿›åº¦] 4/6 SubAgentæ‰§è¡Œä¸­ï¼ˆè°ƒç”¨å·¥å…·+åˆ†æï¼‰...\")\n",
    "            sys.stdout.flush()\n",
    "            subagent_started = True\n",
    "        tool_call_count += 1\n",
    "        elapsed = current_time - start_time\n",
    "        print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] å·¥å…·è°ƒç”¨ {tool_call_count} å®Œæˆ (è€—æ—¶{elapsed:.1f}s)\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # æ£€æµ‹AIæ¶ˆæ¯ï¼ˆæµå¼è¾“å‡ºï¼‰\n",
    "    elif isinstance(message_chunk, AIMessageChunk):\n",
    "        # æ£€æµ‹é¦–ä¸ªtokenè¿”å›\n",
    "        if message_chunk.content and not output_started:\n",
    "            first_token_time = current_time - start_time\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] [è¿›åº¦] 5/6 SubAgentè¿”å›ç»“æœ (æ€»å»¶è¿Ÿ{first_token_time:.1f}s)\")\n",
    "            print(\"[è¿›åº¦] 6/6 æµå¼è¾“å‡ºä¸­...\")\n",
    "            print(f\"\\nå›ç­”ï¼š\", end=\"\")\n",
    "            output_started = True\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # è¾“å‡ºæµå¼å†…å®¹\n",
    "        if message_chunk.content:\n",
    "            print(message_chunk.content, end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            response_text += message_chunk.content\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n\\n[{datetime.now().strftime('%H:%M:%S')}] [å®Œæˆ]\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"[ç»Ÿè®¡] æ€»è€—æ—¶: {total_time:.2f}s | å·¥å…·è°ƒç”¨: {tool_call_count}æ¬¡ | é¦–tokenå»¶è¿Ÿ: {first_token_time:.1f}s\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6926caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜ï¼šå½“å‰é€šèƒ€æ°´å¹³æ€ä¹ˆæ ·ï¼Ÿæ ¹æ®ç»æµç†è®ºåº”è¯¥å¦‚ä½•è§£è¯»ï¼Ÿ\n",
      "------------------------------------------------------------\n",
      "\n",
      "                                        \n",
      "\n",
      "å›ç­”ï¼šæˆ‘æ¥å¸®æ‚¨åˆ†æå½“å‰çš„é€šèƒ€æƒ…å†µã€‚é¦–å…ˆè®©æˆ‘è·å–æœ€æ–°çš„GDPæ•°æ®ï¼Œè¿™é€šå¸¸ä¸é€šèƒ€æ°´å¹³æœ‰å¯†åˆ‡å…³ç³»ã€‚[å·¥å…·] è·å–GDPæ•°æ®... å®Œæˆ\n",
      "[å·¥å…·è°ƒç”¨ 1/5]åŸºäºæœ€æ–°çš„GDPæ•°æ®ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨åˆ†æé€šèƒ€æƒ…å†µï¼š\n",
      "\n",
      "## å½“å‰ç»æµçŠ¶å†µåˆ†æ\n",
      "\n",
      "ä»GDPæ•°æ®æ¥çœ‹ï¼š\n",
      "1. **ç»æµå¢é•¿ç¨³å®š**ï¼š2025å¹´å‰ä¸‰å­£åº¦GDPåŒæ¯”å¢é•¿5.2%ï¼Œä¿æŒåœ¨ä¸­é«˜é€Ÿå¢é•¿åŒºé—´\n",
      "2. **å¢é•¿æ€åŠ¿è‰¯å¥½**ï¼šä»2024å¹´çš„4.8%å¢é•¿åˆ°2025å¹´çš„5.2%ï¼Œæ˜¾ç¤ºç»æµå¤è‹åŠ¿å¤´\n",
      "3. **å­£åº¦è¡¨ç°ç¨³å¥**ï¼šå„å­£åº¦GDPå¢é€Ÿåœ¨5.0%-5.4%ä¹‹é—´ï¼Œæ³¢åŠ¨è¾ƒå°\n",
      "\n",
      "## é€šèƒ€æ°´å¹³çš„ç»æµç†è®ºè§£è¯»\n",
      "\n",
      "### 1. **è²åˆ©æ™®æ–¯æ›²çº¿å…³ç³»**\n",
      "æ ¹æ®ç»å…¸çš„è²åˆ©æ™®æ–¯æ›²çº¿ç†è®ºï¼Œç»æµå¢é•¿ä¸é€šèƒ€å­˜åœ¨æ­£å‘å…³ç³»ï¼š\n",
      "- å½“å‰5.2%çš„ç»æµå¢é•¿å¯èƒ½å¯¹åº”æ¸©å’Œçš„é€šèƒ€æ°´å¹³\n",
      "- ç»æµå¢é•¿ç¨³å®šä½†ä¸è¿‡çƒ­ï¼Œé€šèƒ€å‹åŠ›å¯èƒ½ç›¸å¯¹å¯æ§\n",
      "\n",
      "### 2. **äº§å‡ºç¼ºå£åˆ†æ**\n",
      "- å®é™…GDPå¢é€Ÿé«˜äºæ½œåœ¨å¢é•¿ç‡æ—¶ï¼Œä¼šäº§ç”Ÿæ­£å‘äº§å‡ºç¼ºå£ï¼Œæ¨é«˜é€šèƒ€\n",
      "- å½“å‰5.2%çš„å¢é€Ÿå¦‚æœæ¥è¿‘æ½œåœ¨å¢é•¿ç‡ï¼Œé€šèƒ€å‹åŠ›å¯èƒ½è¾ƒå°\n",
      "\n",
      "### 3. **éœ€æ±‚æ‹‰åŠ¨å‹é€šèƒ€**\n",
      "- ç»æµå¢é•¿ä¸»è¦ç”±æ¶ˆè´¹å’ŒæŠ•èµ„æ‹‰åŠ¨æ—¶ï¼Œå¯èƒ½äº§ç”Ÿéœ€æ±‚æ‹‰åŠ¨å‹é€šèƒ€\n",
      "- éœ€è¦ç»“åˆæ¶ˆè´¹ä»·æ ¼æŒ‡æ•°(CPI)å’Œç”Ÿäº§è€…ä»·æ ¼æŒ‡æ•°(PPI)å…·ä½“åˆ†æ\n",
      "\n",
      "### 4. **æˆæœ¬æ¨åŠ¨å› ç´ **\n",
      "- åŸææ–™ä»·æ ¼ä¸Šæ¶¨ã€åŠ³åŠ¨åŠ›æˆæœ¬ä¸Šå‡ç­‰å¯èƒ½å¸¦æ¥æˆæœ¬æ¨åŠ¨å‹é€šèƒ€\n",
      "- è¿™åœ¨ç»æµå¤è‹é˜¶æ®µè¾ƒä¸ºå¸¸è§\n",
      "\n",
      "## æ”¿ç­–å»ºè®®\n",
      "\n",
      "åŸºäºå½“å‰ç»æµæ•°æ®ï¼š\n",
      "1. **è´§å¸æ”¿ç­–**ï¼šå¦‚æœé€šèƒ€æ¸©å’Œï¼Œå¯ç»´æŒç›¸å¯¹å®½æ¾çš„è´§å¸æ”¿ç­–æ”¯æŒç»æµå¢é•¿\n",
      "2. **è´¢æ”¿æ”¿ç­–**ï¼šå¯ç»§ç»­å®æ–½ç§¯æçš„è´¢æ”¿æ”¿ç­–ï¼Œä½†è¦å…³æ³¨é€šèƒ€é¢„æœŸç®¡ç†\n",
      "3. **ç»“æ„æ€§æ”¹é©**ï¼šé€šè¿‡ä¾›ç»™ä¾§æ”¹é©ç¼“è§£æˆæœ¬æ¨åŠ¨å‹é€šèƒ€å‹åŠ›\n",
      "\n",
      "**æ³¨æ„**ï¼šè¦å‡†ç¡®è¯„ä¼°é€šèƒ€æ°´å¹³ï¼Œè¿˜éœ€è¦ç»“åˆCPIã€PPIã€æ ¸å¿ƒé€šèƒ€ç‡ç­‰å…·ä½“ä»·æ ¼æŒ‡æ•°æ•°æ®ã€‚å½“å‰GDPæ•°æ®æ˜¾ç¤ºç»æµç¨³å¥å¢é•¿ï¼Œè¿™é€šå¸¸å¯¹åº”æ¸©å’Œçš„é€šèƒ€ç¯å¢ƒï¼Œä½†å…·ä½“é€šèƒ€æ°´å¹³éœ€è¦æŸ¥çœ‹ä»·æ ¼æŒ‡æ•°æ•°æ®æ‰èƒ½ç²¾ç¡®åˆ¤æ–­ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•2ï¼šé€šèƒ€åˆ†æï¼ˆå¸¦è¿›åº¦æç¤ºï¼‰\n",
    "import sys\n",
    "import time\n",
    "from langchain_core.messages import AIMessageChunk, ToolMessage\n",
    "\n",
    "test_query_2 = \"å½“å‰é€šèƒ€æ°´å¹³æ€ä¹ˆæ ·ï¼Ÿæ ¹æ®ç»æµç†è®ºåº”è¯¥å¦‚ä½•è§£è¯»ï¼Ÿ\"\n",
    "print(f\"é—®é¢˜ï¼š{test_query_2}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\n[Agentåˆ†æä¸­...]\", end=\"\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "tool_call_count = 0\n",
    "output_started = False\n",
    "\n",
    "for message_chunk, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": test_query_2}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if isinstance(message_chunk, ToolMessage):\n",
    "        tool_call_count += 1\n",
    "        print(f\"\\r[å·¥å…·è°ƒç”¨ {tool_call_count}/5]\", end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    elif isinstance(message_chunk, AIMessageChunk) and message_chunk.content:\n",
    "        if not output_started:\n",
    "            print(\"\\r\" + \" \" * 40)\n",
    "            print(\"\\nå›ç­”ï¼š\", end=\"\")\n",
    "            output_started = True\n",
    "\n",
    "        print(message_chunk.content, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08e90465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜ï¼šPMIæ•°æ®æ˜¾ç¤ºç»æµè¶‹åŠ¿å¦‚ä½•ï¼Ÿç»“åˆç»æµå‘¨æœŸç†è®ºåˆ†æ\n",
      "------------------------------------------------------------\n",
      "\n",
      "                                        \n",
      "\n",
      "å›ç­”ï¼šæˆ‘ä¸»è¦ä¸“æ³¨äºGDPæ•°æ®åˆ†æï¼Œç›®å‰æ— æ³•ç›´æ¥è·å–PMIæ•°æ®æ¥åˆ†æç»æµè¶‹åŠ¿ã€‚ä¸è¿‡ï¼Œæˆ‘å¯ä»¥å…ˆä¸ºæ‚¨æä¾›æœ€æ–°çš„GDPæ•°æ®ï¼Œç„¶ååŸºäºç»æµå‘¨æœŸç†è®ºæ¥åˆ†ææ•´ä½“ç»æµçŠ¶å†µã€‚\n",
      "\n",
      "è®©æˆ‘è·å–æœ€æ–°çš„å­£åº¦GDPæ•°æ®ï¼š[å·¥å…·] è·å–GDPæ•°æ®... å®Œæˆ\n",
      "[å·¥å…·è°ƒç”¨ 1/5]åŸºäºæœ€æ–°çš„GDPæ•°æ®ï¼Œæˆ‘å¯ä»¥ä»ç»æµå‘¨æœŸç†è®ºçš„è§’åº¦ä¸ºæ‚¨åˆ†æå½“å‰çš„ç»æµè¶‹åŠ¿ï¼š\n",
      "\n",
      "## GDPæ•°æ®åˆ†æ\n",
      "\n",
      "ä»æ•°æ®å¯ä»¥çœ‹å‡ºï¼š\n",
      "1. **2024å¹´å…¨å¹´å¢é•¿5.0%**ï¼Œç»æµä¿æŒç¨³å®šå¢é•¿\n",
      "2. **2025å¹´ç¬¬ä¸€å­£åº¦åŒæ¯”å¢é•¿5.4%**ï¼Œæ˜¾ç¤ºå‡ºè¾ƒå¼ºçš„å¢é•¿åŠ¿å¤´\n",
      "3. **2025å¹´å‰ä¸‰å­£åº¦ç´¯è®¡å¢é•¿5.2%**ï¼Œå¢é•¿ç•¥æœ‰æ”¾ç¼“ä½†ä»ä¿æŒç¨³å¥\n",
      "\n",
      "## ç»æµå‘¨æœŸç†è®ºåˆ†æ\n",
      "\n",
      "### 1. **å½“å‰å‘¨æœŸä½ç½®**\n",
      "- ä»GDPå¢é€Ÿçœ‹ï¼ˆ5.0%-5.4%ï¼‰ï¼Œç»æµå¤„äº**æ‰©å¼ æœŸ**æˆ–**ç¹è£æœŸ**çš„æ—©æœŸé˜¶æ®µ\n",
      "- å¢é€Ÿç›¸å¯¹ç¨³å®šï¼Œæ²¡æœ‰å‡ºç°æ˜æ˜¾çš„è¿‡çƒ­è¿¹è±¡\n",
      "\n",
      "### 2. **å‘¨æœŸç‰¹å¾**\n",
      "- **æ‰©å¼ ç‰¹å¾**ï¼šè¿ç»­å¤šä¸ªå­£åº¦ä¿æŒ5%ä»¥ä¸Šçš„å¢é•¿\n",
      "- **ç¨³å®šæ€§**ï¼šå¢é€Ÿæ³¢åŠ¨è¾ƒå°ï¼ˆ4.8%-5.4%ï¼‰ï¼Œæ˜¾ç¤ºå‡ºè¾ƒå¥½çš„ç»æµéŸ§æ€§\n",
      "- **å¯æŒç»­æ€§**ï¼šæ²¡æœ‰å‡ºç°æ€¥å‰§åŠ é€Ÿæˆ–å‡é€Ÿï¼Œç¬¦åˆå¥åº·æ‰©å¼ çš„ç‰¹å¾\n",
      "\n",
      "### 3. **æ½œåœ¨é£é™©ç‚¹**\n",
      "- 2025å¹´å‰ä¸‰å­£åº¦å¢é€Ÿï¼ˆ5.2%ï¼‰ç•¥ä½äºç¬¬ä¸€å­£åº¦ï¼ˆ5.4%ï¼‰ï¼Œéœ€è¦å…³æ³¨æ˜¯å¦å‡ºç°å¢é•¿æ”¾ç¼“è¶‹åŠ¿\n",
      "- éœ€è¦ç»“åˆå…¶ä»–æŒ‡æ ‡ï¼ˆå¦‚PMIã€å·¥ä¸šå¢åŠ å€¼ã€æ¶ˆè´¹æ•°æ®ç­‰ï¼‰æ¥å…¨é¢åˆ¤æ–­ç»æµåŠ¨èƒ½\n",
      "\n",
      "### 4. **æ”¿ç­–å»ºè®®**\n",
      "- **æ‰©å¼ æœŸç®¡ç†**ï¼šåº”å…³æ³¨é€šèƒ€å‹åŠ›å’Œèµ„äº§ä»·æ ¼æ³¡æ²«\n",
      "- **ç»“æ„æ€§è°ƒæ•´**ï¼šåˆ©ç”¨å¢é•¿çª—å£æœŸæ¨è¿›ç»æµç»“æ„ä¼˜åŒ–\n",
      "- **é£é™©é˜²èŒƒ**ï¼šä¸ºå¯èƒ½çš„å‘¨æœŸè½¬æ¢åšå¥½å‡†å¤‡\n",
      "\n",
      "## å…³äºPMIæ•°æ®çš„è¡¥å……è¯´æ˜\n",
      "\n",
      "è™½ç„¶æˆ‘æ— æ³•ç›´æ¥è·å–PMIæ•°æ®ï¼Œä½†ä»ç»æµå‘¨æœŸç†è®ºæ¥çœ‹ï¼š\n",
      "- **PMIä¸GDPçš„å…³ç³»**ï¼šPMIé€šå¸¸é¢†å…ˆäºGDPï¼Œæ˜¯ç»æµå‘¨æœŸçš„å…ˆè¡ŒæŒ‡æ ‡\n",
      "- **ç»¼åˆåˆ†æçš„é‡è¦æ€§**ï¼šç†æƒ³çš„ç»æµåˆ†æéœ€è¦ç»“åˆPMIï¼ˆåˆ¶é€ ä¸šæ™¯æ°”åº¦ï¼‰ã€GDPï¼ˆæ€»é‡å¢é•¿ï¼‰ã€å°±ä¸šã€é€šèƒ€ç­‰å¤šç»´åº¦æ•°æ®\n",
      "- **å‘¨æœŸåˆ¤æ–­**ï¼šPMIæŒç»­é«˜äº50è£æ¯çº¿é€šå¸¸è¡¨æ˜ç»æµå¤„äºæ‰©å¼ æœŸ\n",
      "\n",
      "**å»ºè®®**ï¼šè¦å…¨é¢äº†è§£ç»æµè¶‹åŠ¿ï¼Œå»ºè®®åŒæ—¶å…³æ³¨PMIã€å·¥ä¸šå¢åŠ å€¼ã€ç¤¾ä¼šæ¶ˆè´¹å“é›¶å”®æ€»é¢ã€å›ºå®šèµ„äº§æŠ•èµ„ç­‰é«˜é¢‘æ•°æ®ï¼Œç»“åˆGDPæ•°æ®è¿›è¡Œç»¼åˆåˆ†æã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•3ï¼šPMIç»æµè¶‹åŠ¿åˆ†æï¼ˆå¸¦è¿›åº¦æç¤ºï¼‰\n",
    "import sys\n",
    "import time\n",
    "from langchain_core.messages import AIMessageChunk, ToolMessage\n",
    "\n",
    "test_query_3 = \"PMIæ•°æ®æ˜¾ç¤ºç»æµè¶‹åŠ¿å¦‚ä½•ï¼Ÿç»“åˆç»æµå‘¨æœŸç†è®ºåˆ†æ\"\n",
    "print(f\"é—®é¢˜ï¼š{test_query_3}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\n[Agentåˆ†æä¸­...]\", end=\"\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "tool_call_count = 0\n",
    "output_started = False\n",
    "\n",
    "for message_chunk, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": test_query_3}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if isinstance(message_chunk, ToolMessage):\n",
    "        tool_call_count += 1\n",
    "        print(f\"\\r[å·¥å…·è°ƒç”¨ {tool_call_count}/5]\", end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    elif isinstance(message_chunk, AIMessageChunk) and message_chunk.content:\n",
    "        if not output_started:\n",
    "            print(\"\\r\" + \" \" * 40)\n",
    "            print(\"\\nå›ç­”ï¼š\", end=\"\")\n",
    "            output_started = True\n",
    "\n",
    "        print(message_chunk.content, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2e5ef",
   "metadata": {},
   "source": [
    "## ä»»åŠ¡3ï¼šå®Œæ•´æµ‹è¯•ï¼ˆ10ä¸ªåœºæ™¯ï¼‰\n",
    "\n",
    "æµ‹è¯•SubAgentçš„ç»¼åˆåˆ†æèƒ½åŠ›ï¼Œè¯„ä¼°è¾“å‡ºè´¨é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a49d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…±10ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒæŒ‰éš¾åº¦é€’å¢\n",
      "1. 2024å¹´GDPå¢é•¿ç‡æ˜¯å¤šå°‘ï¼Ÿ\n",
      "2. å½“å‰çš„é€šèƒ€æ°´å¹³å¦‚ä½•ï¼Ÿ\n",
      "3. æœ€æ–°çš„PMIæ•°æ®æ˜¯å¤šå°‘ï¼Ÿ\n",
      "4. å½“å‰ç»æµå¤„äºä»€ä¹ˆå‘¨æœŸï¼Ÿ\n",
      "5. ç»æµå‘¨æœŸè½¬æŠ˜çš„ä¿¡å·æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "6. ä»€ä¹ˆæŒ‡æ ‡å˜åŒ–ä¼šé¢„ç¤ºå‘¨æœŸè½¬æŠ˜ï¼Ÿ\n",
      "7. æ ¹æ®å½“å‰ç»æµå‘¨æœŸï¼Œåº”è¯¥é…ç½®ä»€ä¹ˆèµ„äº§ï¼Ÿ\n",
      "8. æŠ•èµ„æ—¶é’Ÿå½“å‰å¤„äºå“ªä¸ªé˜¶æ®µï¼Ÿ\n",
      "9. ç»™å‡ºå½“å‰å®è§‚ç»æµçš„æ•´ä½“åˆ¤æ–­\n",
      "10. ä»å®è§‚è§’åº¦çœ‹ï¼Œå‘¨æœŸæ€§è¡Œä¸šæŠ•èµ„æœºä¼šå¦‚ä½•ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# 10ä¸ªæµ‹è¯•åœºæ™¯ï¼ˆæŒ‰éš¾åº¦é€’å¢ï¼‰\n",
    "test_questions = [\n",
    "    # åŸºç¡€æ•°æ®æŸ¥è¯¢ï¼ˆç®€å•ï¼‰\n",
    "    \"2024å¹´GDPå¢é•¿ç‡æ˜¯å¤šå°‘ï¼Ÿ\",\n",
    "    \"å½“å‰çš„é€šèƒ€æ°´å¹³å¦‚ä½•ï¼Ÿ\",\n",
    "    \"æœ€æ–°çš„PMIæ•°æ®æ˜¯å¤šå°‘ï¼Ÿ\",\n",
    "\n",
    "    # å‘¨æœŸåˆ¤æ–­ï¼ˆä¸­ç­‰ï¼‰\n",
    "    \"å½“å‰ç»æµå¤„äºä»€ä¹ˆå‘¨æœŸï¼Ÿ\",\n",
    "    \"ç»æµå‘¨æœŸè½¬æŠ˜çš„ä¿¡å·æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"ä»€ä¹ˆæŒ‡æ ‡å˜åŒ–ä¼šé¢„ç¤ºå‘¨æœŸè½¬æŠ˜ï¼Ÿ\",\n",
    "\n",
    "    # æŠ•èµ„ç­–ç•¥ï¼ˆå›°éš¾ï¼‰\n",
    "    \"æ ¹æ®å½“å‰ç»æµå‘¨æœŸï¼Œåº”è¯¥é…ç½®ä»€ä¹ˆèµ„äº§ï¼Ÿ\",\n",
    "    \"æŠ•èµ„æ—¶é’Ÿå½“å‰å¤„äºå“ªä¸ªé˜¶æ®µï¼Ÿ\",\n",
    "\n",
    "    # ç»¼åˆåˆ†æï¼ˆæœ€éš¾ï¼‰\n",
    "    \"ç»™å‡ºå½“å‰å®è§‚ç»æµçš„æ•´ä½“åˆ¤æ–­\",\n",
    "    \"ä»å®è§‚è§’åº¦çœ‹ï¼Œå‘¨æœŸæ€§è¡Œä¸šæŠ•èµ„æœºä¼šå¦‚ä½•ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(f\"å…±{len(test_questions)}ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒæŒ‰éš¾åº¦é€’å¢\")\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcfeb0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•è„šæœ¬å·²å‡†å¤‡ï¼Œå–æ¶ˆä¸‰å¼•å·å¯è¿è¡Œ\n"
     ]
    }
   ],
   "source": [
    "# æ‰¹é‡æµ‹è¯•ï¼ˆæ³¨é‡ŠçŠ¶æ€ï¼Œéœ€è¦æ—¶å–æ¶ˆä¸‹é¢çš„ä¸‰å¼•å·è¿è¡Œï¼‰\n",
    "\"\"\"\n",
    "results = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"æµ‹è¯• {i}/{len(test_questions)}: {question}\")\n",
    "    print('='*60)\n",
    "\n",
    "    try:\n",
    "        result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": question}]})\n",
    "        response_text = result[\"messages\"][-1].content\n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'response': response_text,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        print(response_text)\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "        print(f\"[é”™è¯¯] é”™è¯¯: {e}\")\n",
    "\n",
    "# ä¿å­˜æµ‹è¯•ç»“æœ\n",
    "import json\n",
    "with open('../data/stage2_test_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n[å®Œæˆ] æµ‹è¯•å®Œæˆï¼æˆåŠŸ: {sum(1 for r in results if r['status']=='success')}/{len(results)}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"æµ‹è¯•è„šæœ¬å·²å‡†å¤‡ï¼Œå–æ¶ˆä¸‰å¼•å·å¯è¿è¡Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ee4a9",
   "metadata": {},
   "source": [
    "## è¾“å‡ºè´¨é‡è¯„ä¼°æ ‡å‡†\n",
    "\n",
    "**æ•°æ®å‡†ç¡®æ€§**ï¼ˆ30åˆ†ï¼‰ï¼š\n",
    "- [å¿…é¡»] å¼•ç”¨æ­£ç¡®æ¥æºï¼ˆ\"æ ¹æ®AKShareæœ€æ–°æ•°æ®...ï¼‰\n",
    "- [å¿…é¡»] æ•°æ®æ—¶é—´æ˜ç¡®ï¼ˆ\"2024å¹´11æœˆ...\"ï¼‰\n",
    "- [å¿…é¡»] æ•°å€¼å‡†ç¡®æ— è¯¯\n",
    "\n",
    "**åˆ†æä¸“ä¸šæ€§**ï¼ˆ40åˆ†ï¼‰ï¼š\n",
    "- [å¿…é¡»] è¿ç”¨ç†è®ºæ¡†æ¶ï¼ˆ\"æ ¹æ®ç»æµå‘¨æœŸç†è®º...\"ï¼‰\n",
    "- [å¿…é¡»] åˆ†æé€»è¾‘æ¸…æ™°ï¼ˆæ•°æ®â†’è¶‹åŠ¿â†’åŸå› â†’å½±å“ï¼‰\n",
    "- [å¿…é¡»] ç»“åˆçŸ¥è¯†åº“å†…å®¹\n",
    "\n",
    "**ç»“è®ºæ¸…æ™°åº¦**ï¼ˆ30åˆ†ï¼‰ï¼š\n",
    "- [å¿…é¡»] ç»™å‡ºæ˜ç¡®åˆ¤æ–­ï¼ˆ\"å½“å‰å¤„äºXXå‘¨æœŸ\"ï¼‰\n",
    "- [å¿…é¡»] æå‡ºå¯è¡Œå»ºè®®ï¼ˆ\"å»ºè®®é…ç½®XXèµ„äº§\"ï¼‰\n",
    "- [å¿…é¡»] æ˜“äºç†è§£ï¼ˆéä¸“ä¸šäººå£«èƒ½çœ‹æ‡‚ï¼‰\n",
    "\n",
    "**æ€»åˆ†â‰¥80åˆ†ï¼šä¼˜ç§€** | **60-79åˆ†ï¼šè‰¯å¥½** | **<60åˆ†ï¼šéœ€ä¼˜åŒ–**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyst_chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
