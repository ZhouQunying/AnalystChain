{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../config/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fe40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf60c6f",
   "metadata": {},
   "source": [
    "### 通过一次大模型调用总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"请对以下内容写一个简明的总结：\\\\n\\\\n{context}\")]\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "for token in chain.invoke({\"context\": docs}):\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c79d5d",
   "metadata": {},
   "source": [
    "### 通过Map-Reduce架构并行化总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfe88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.constants import Send\n",
    "from langchain.chains.combine_documents.reduce import (\n",
    "    acollapse_docs,\n",
    "    split_list_of_docs,\n",
    ")\n",
    "\n",
    "# 单次处理的最大token数量\n",
    "token_max = 1000\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_message(\n",
    "    [(\"system\", \"写下以下内容的简明摘要：{context}\")]\n",
    ")\n",
    "\n",
    "reduce_template = \"\"\"\n",
    "以下是一组摘要：\n",
    "{docs}\n",
    "请将这些内容提炼成一个最终的、综合的摘要，概括主要主题。\n",
    "\"\"\"\n",
    "reduce_prompt = ChatPromptTemplate(\n",
    "    [(\"human\", reduce_template)]\n",
    ")\n",
    "\n",
    "# 主图状态：管理整个摘要流程的数据流\n",
    "class OverallState(TypedDict):\n",
    "    contents: List[str]\n",
    "    summaries: Annotated[list, operator.add]\n",
    "    collapsed_summaries: List[Document]\n",
    "    final_summary: str\n",
    "\n",
    "class SummaryState(TypedDict):\n",
    "    content: str\n",
    "\n",
    "# 计算文档列表的总token数量\n",
    "def length_function(documents: List[Document]) -> int:\n",
    "    return sum(llm.get_num_token(doc.page_content) for doc in documents)\n",
    "\n",
    "# 为每个文档内容创建一个Send对象，实现并行处理\n",
    "def map_summaries(state: OverallState):\n",
    "    return [\n",
    "        Send({\"content\": content}) for content in state[\"contents\"]\n",
    "    ]\n",
    "\n",
    "# 将多个摘要合并成一个\n",
    "async def _reduce(input: dict) -> str:\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# 判断是否需要继续合并摘要\n",
    "def should_collapse(state: OverallState):\n",
    "    num_tokens = should_collapse(state[\"collapsed_summeries\"])\n",
    "\n",
    "    if num_tokens > token_max:\n",
    "        return \"collapse_summeries\"\n",
    "    else:\n",
    "        return \"generate_final_summary\"\n",
    "\n",
    "# 为单个文档生成摘要（Map阶段的核心函数）\n",
    "async def generate_summary(state: SummaryState):\n",
    "    prompt = map_prompt.invoke(state[\"content\"])\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return {\"summaries\": response.content}\n",
    "\n",
    "# 收集摘要：将并行生成的摘要收集成文档列表\n",
    "def collect_summaries(state: OverallState):\n",
    "    return {\"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]}\n",
    "\n",
    "# 智能合并摘要：根据token限制分批合并摘要\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    doc_lists = split_list_of_docs(\n",
    "        state[\"collapsed_summaries\"],\n",
    "        length_function,\n",
    "        token_max,\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for doc_list in doc_lists:\n",
    "        results.append(await acollapse_docs(doc_list, _reduce))\n",
    "\n",
    "    return {\"collapsed_summaries\": results}\n",
    "\n",
    "# 生成最终摘要结果\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\": response}\n",
    "\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\", generate_summary)\n",
    "graph.add_node(\"collect_summaries\", collect_summaries)\n",
    "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
    "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
    "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
    "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
    "graph.add_edge(\"generate_final_summary\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for step in app.astream(\n",
    "    {\"contents\": [doc.content for doc in split_docs]},\n",
    "    {\"recursion_limit\": 10}\n",
    "):\n",
    "    print(list(step.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyst_chain (conda)",
   "language": "python",
   "name": "analyst_chain"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
