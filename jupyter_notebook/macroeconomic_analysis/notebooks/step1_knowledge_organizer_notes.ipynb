{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# çŸ¥è¯†æ–‡ä»¶æ‰«æä¸æ™ºèƒ½åˆ†ç»„ - å¸¦è¯¦ç»†æ³¨é‡Šç‰ˆ\n",
        "\n",
        "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "è¿™ä¸ªnotebookä¼š**è¾¹åšè¾¹å­¦**,è¯¦ç»†è§£é‡Š:\n",
        "- æ¯ä¸ªPythonç‰¹æ€§çš„ä½œç”¨\n",
        "- æ¯ä¸ªAPIçš„ç”¨æ³•\n",
        "- ä¸ºä»€ä¹ˆè¿™æ ·å†™\n",
        "- å¸¸è§é—®é¢˜å’Œæ›¿ä»£æ–¹æ¡ˆ\n",
        "\n",
        "**é€‚åˆäººç¾¤**: Pythonåˆå­¦è€…ã€LangChainåˆå­¦è€…\n",
        "\n",
        "**å­¦ä¹ æ–¹å¼**: æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªcell,ä»”ç»†é˜…è¯»æ³¨é‡Š\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. å¯¼å…¥ä¾èµ– - æ¯ä¸ªimportçš„ä½œç”¨\n",
        "\n",
        "**importçš„ä½œç”¨**: å¯¼å…¥Pythonçš„æ ‡å‡†åº“æˆ–ç¬¬ä¸‰æ–¹åº“,è®©æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒä»¬çš„åŠŸèƒ½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# re: æ­£åˆ™è¡¨è¾¾å¼åº“ (Regular Expression)\n",
        "# ============================================================\n",
        "# ä½œç”¨: å¤„ç†æ–‡æœ¬,æŸ¥æ‰¾ã€æ›¿æ¢ã€æå–ç‰¹å®šæ¨¡å¼çš„å­—ç¬¦ä¸²\n",
        "# ä¾‹å¦‚: ä»\"01ç¬¬ä¸€èŠ‚\"ä¸­æå–æ•°å­—\"01\"\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/re.html\n",
        "# å£è¯€: æ­£åˆ™è¡¨è¾¾å¼ = æ–‡æœ¬çš„æŸ¥æ‰¾å·¥å…·\n",
        "import re\n",
        "\n",
        "# ============================================================\n",
        "# json: JSONæ ¼å¼å¤„ç†åº“\n",
        "# ============================================================\n",
        "# ä½œç”¨: å°†Pythonå­—å…¸è½¬æ¢ä¸ºJSONæ ¼å¼(ç”¨äºä¿å­˜æ–‡ä»¶)\n",
        "# æˆ–å°†JSONæ–‡ä»¶è¯»å–ä¸ºPythonå­—å…¸(ç”¨äºè¯»å–æ–‡ä»¶)\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/json.html\n",
        "# å£è¯€: JSON = æ•°æ®çš„äº¤æ¢æ ¼å¼(åƒExcelä¸€æ ·,ä½†æ›´è½»é‡)\n",
        "import json\n",
        "\n",
        "# ============================================================\n",
        "# Path: æ–‡ä»¶è·¯å¾„å¤„ç†ç±» (æ¥è‡ªpathlib)\n",
        "# ============================================================\n",
        "# ä½œç”¨: æ¯”å­—ç¬¦ä¸²(str)æ›´å®‰å…¨åœ°å¤„ç†æ–‡ä»¶è·¯å¾„\n",
        "# ä¸ºä»€ä¹ˆç”¨Pathè€Œä¸æ˜¯str?\n",
        "#   - str: \"/user/file.txt\" (å®¹æ˜“å‡ºé”™,windows/macè·¯å¾„ä¸åŒ)\n",
        "#   - Path: Path(\"/user/file.txt\") (è‡ªåŠ¨é€‚é…æ“ä½œç³»ç»Ÿ)\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/pathlib.html\n",
        "# å£è¯€: Path = æ™ºèƒ½çš„æ–‡ä»¶è·¯å¾„(ä¼šè‡ªåŠ¨å¤„ç†æ–œæ æ–¹å‘)\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# typing: ç±»å‹æç¤ºåº“\n",
        "# ============================================================\n",
        "# ä½œç”¨: å‘Šè¯‰åˆ«äºº(å’ŒIDE)è¿™ä¸ªå˜é‡åº”è¯¥æ˜¯ä»€ä¹ˆç±»å‹\n",
        "# ä¾‹å¦‚: def add(a: int, b: int) -> int:\n",
        "#       è¡¨ç¤º: aå’Œbåº”è¯¥æ˜¯æ•´æ•°,è¿”å›å€¼ä¹Ÿæ˜¯æ•´æ•°\n",
        "# Dict = å­—å…¸ç±»å‹, List = åˆ—è¡¨ç±»å‹, Tuple = å…ƒç»„ç±»å‹ç­‰\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/typing.html\n",
        "# å£è¯€: Type Hints = ç»™ä»£ç åŠ ä¸Š\"è¯´æ˜ä¹¦\"\n",
        "from typing import Dict, List, Tuple, Optional, Set\n",
        "\n",
        "# ============================================================\n",
        "# dataclass: æ•°æ®ç±»è£…é¥°å™¨\n",
        "# ============================================================\n",
        "# ä½œç”¨: è‡ªåŠ¨ç”Ÿæˆ__init__ç­‰æ–¹æ³•,å‡å°‘é‡å¤ä»£ç \n",
        "# ä¸ºä»€ä¹ˆç”¨dataclass?\n",
        "#   - ä¼ ç»Ÿæ–¹å¼: è¦è‡ªå·±å†™__init__, __repr__ç­‰,å¾ˆç¹ç\n",
        "#   - dataclass: è‡ªåŠ¨ç”Ÿæˆ,åªéœ€å®šä¹‰å±æ€§\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/dataclasses.html\n",
        "# å£è¯€: dataclass = è‡ªåŠ¨å†™åˆå§‹åŒ–ä»£ç çš„å·¥å…·\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "# ============================================================\n",
        "# defaultdict: å¸¦é»˜è®¤å€¼çš„å­—å…¸\n",
        "# ============================================================\n",
        "# ä½œç”¨: è®¿é—®ä¸å­˜åœ¨çš„keyæ—¶,è‡ªåŠ¨åˆ›å»ºé»˜è®¤å€¼(ä¸ä¼šæŠ¥é”™)\n",
        "# æ™®é€šå­—å…¸: d = {}; d['a'] â†’ KeyError é”™è¯¯!\n",
        "# defaultdict: d = defaultdict(dict); d['a'] â†’ {} è‡ªåŠ¨åˆ›å»º!\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/collections.html\n",
        "# å£è¯€: defaultdict = æ°¸è¿œä¸ä¼šæŠ¥\"keyä¸å­˜åœ¨\"é”™è¯¯çš„å­—å…¸\n",
        "from collections import defaultdict\n",
        "\n",
        "# ============================================================\n",
        "# SequenceMatcher: åºåˆ—ç›¸ä¼¼åº¦è®¡ç®—å™¨\n",
        "# ============================================================\n",
        "# ä½œç”¨: è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²æœ‰å¤šç›¸ä¼¼(0-1çš„åˆ†æ•°)\n",
        "# ä¾‹å¦‚: \"ä¸­å›½ç»æµçš„ä¸‰é©¾é©¬è½¦\" vs \"ä¸­å›½ç»æµä¸‰é©¾é©¬è½¦\" â†’ 0.95 (å¾ˆç›¸ä¼¼)\n",
        "#      \"ä¸‰é©¾é©¬è½¦\" vs \"æ¶ˆè´¹\" â†’ 0.0 (å®Œå…¨ä¸åŒ)\n",
        "# ç®—æ³•: åŸºäºæœ€é•¿å…¬å…±å­åºåˆ—(LCS)\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/difflib.html\n",
        "# å£è¯€: SequenceMatcher = æ–‡æœ¬ç›¸ä¼¼åº¦æ‰“åˆ†å™¨\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# ============================================================\n",
        "# IntEnum: æ•´æ•°æšä¸¾ç±»\n",
        "# ============================================================\n",
        "# ä½œç”¨: å®šä¹‰ä¸€ç»„æœ‰æ„ä¹‰çš„å¸¸é‡(é¿å…ä½¿ç”¨é­”æ³•æ•°å­—)\n",
        "# ä¸ºä»€ä¹ˆç”¨æšä¸¾?\n",
        "#   - ä¸ç”¨æšä¸¾: priority = 1 (1æ˜¯ä»€ä¹ˆæ„æ€?ä¸æ¸…æ¥š!)\n",
        "#   - ç”¨æšä¸¾: priority = FilePriority.PDF_NOTE (ä¸€çœ‹å°±æ‡‚!)\n",
        "# å®˜æ–¹æ–‡æ¡£: https://docs.python.org/3/library/enum.html\n",
        "# å£è¯€: Enum = ç»™æ•°å­—å–åå­—,è®©ä»£ç æ›´æ˜“è¯»\n",
        "from enum import IntEnum\n",
        "\n",
        "print(\"âœ… ä¾èµ–å¯¼å…¥å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. æ•°æ®ç»“æ„å®šä¹‰\n",
        "\n",
        "### çŸ¥è¯†ç‚¹: ä¸ºä»€ä¹ˆè¦å®šä¹‰æ•°æ®ç»“æ„?\n",
        "\n",
        "**ç±»æ¯”**: æ•°æ®ç»“æ„å°±åƒ\"è¡¨æ ¼çš„åˆ—å\"\n",
        "\n",
        "|  æ–‡ä»¶è·¯å¾„  |  åŸå§‹å  |  æ¸…æ´—åå  |  åºå·  |  ä¼˜å…ˆçº§  |\n",
        "|-----------|---------|-----------|-------|---------|\n",
        "| /path/a.pdf | 01...pdf | 01ç¬¬ä¸€èŠ‚ |   1   | PDF_NOTE |\n",
        "\n",
        "å¦‚æœæ²¡æœ‰æ•°æ®ç»“æ„,ä»£ç ä¼šå¾ˆæ··ä¹±:\n",
        "```python\n",
        "# æ··ä¹±çš„æ–¹å¼ (ä¸æ¨è)\n",
        "file_data = [\"/path/a.pdf\", \"01...pdf\", \"01ç¬¬ä¸€èŠ‚\", 1, \"PDF_NOTE\"]\n",
        "# é—®é¢˜: file_data[2]æ˜¯ä»€ä¹ˆ? è¦è®°ä½é¡ºåº,å®¹æ˜“å‡ºé”™!\n",
        "```\n",
        "\n",
        "æœ‰äº†æ•°æ®ç»“æ„:\n",
        "```python\n",
        "# æ¸…æ™°çš„æ–¹å¼ (æ¨è)\n",
        "file_info = FileInfo(path=..., original_name=..., ...)\n",
        "# ä¼˜åŠ¿: file_info.cleaned_name ä¸€çœ‹å°±æ‡‚!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# æ•°æ®ç»“æ„1: FilePriority - æ–‡ä»¶ä¼˜å…ˆçº§æšä¸¾\n",
        "# ============================================================\n",
        "\n",
        "class FilePriority(IntEnum):\n",
        "    \"\"\"\n",
        "    æ–‡ä»¶ä¼˜å…ˆçº§æšä¸¾\n",
        "\n",
        "    ä¸ºä»€ä¹ˆè¦å®šä¹‰ä¼˜å…ˆçº§?\n",
        "    ç­”: åŒä¸€çŸ¥è¯†å—æœ‰3ä¸ªæ–‡ä»¶(pdf/doc/ppt),æˆ‘ä»¬åªæƒ³å¤„ç†æœ€å®Œæ•´çš„é‚£ä¸ª\n",
        "\n",
        "    ä¼˜å…ˆçº§è§„åˆ™(æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜):\n",
        "    1. PDFç¬”è®° â†’ è¯¾ç¨‹ç¬”è®°,å†…å®¹æœ€å®Œæ•´\n",
        "    2. Wordæ–‡æ¡£ â†’ è¯¦ç»†æ–‡å­—è¯´æ˜\n",
        "    3. æ™®é€šPDF â†’ å¯èƒ½æ˜¯æ‰«æä»¶\n",
        "    4. PPT â†’ å›¾è¡¨å¤šä½†æ–‡å­—å°‘\n",
        "\n",
        "    IntEnumçš„ä½œç”¨:\n",
        "    - ç»§æ‰¿è‡ªint,å¯ä»¥å½“æ•°å­—ç”¨ (FilePriority.PDF_NOTE == 1 â†’ True)\n",
        "    - æœ‰åå­—,å¯è¯»æ€§å¥½ (priority.name â†’ \"PDF_NOTE\")\n",
        "    \"\"\"\n",
        "    PDF_NOTE = 1      # PDFç¬”è®°ï¼šå†…å®¹æœ€å®Œæ•´\n",
        "    WORD_DOC = 2      # Wordæ–‡æ¡£ï¼šè¯¦ç»†è¯´æ˜\n",
        "    PDF_REGULAR = 3   # æ™®é€šPDF\n",
        "    POWERPOINT = 4    # PPTï¼šå›¾è¡¨å¤šä½†æ–‡å­—å°‘\n",
        "    UNKNOWN = 99      # æœªçŸ¥æ ¼å¼\n",
        "\n",
        "# æµ‹è¯•ä¸€ä¸‹\n",
        "print(f\"PDFç¬”è®°çš„ä¼˜å…ˆçº§æ•°å­—: {FilePriority.PDF_NOTE}\")  # è¾“å‡º: 1\n",
        "print(f\"PDFç¬”è®°çš„ä¼˜å…ˆçº§åç§°: {FilePriority.PDF_NOTE.name}\")  # è¾“å‡º: PDF_NOTE\n",
        "print(f\"PDFç¬”è®° < Word? {FilePriority.PDF_NOTE < FilePriority.WORD_DOC}\")  # True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# æ•°æ®ç»“æ„2: FileInfo - æ–‡ä»¶ä¿¡æ¯ç±»\n",
        "# ============================================================\n",
        "\n",
        "@dataclass  # è£…é¥°å™¨: å‘Šè¯‰Python\"è¿™æ˜¯ä¸€ä¸ªæ•°æ®ç±»\"\n",
        "class FileInfo:\n",
        "    \"\"\"\n",
        "    æ–‡ä»¶ä¿¡æ¯æ•°æ®ç±»\n",
        "\n",
        "    dataclassçš„é­”æ³•:\n",
        "    ----------------\n",
        "    æ²¡æœ‰@dataclassæ—¶,ä½ è¦å†™:\n",
        "        def __init__(self, path, original_name, ...):\n",
        "            self.path = path\n",
        "            self.original_name = original_name\n",
        "            ...\n",
        "        def __repr__(self):\n",
        "            return f\"FileInfo(...)\"\n",
        "\n",
        "    æœ‰äº†@dataclass,Pythonè‡ªåŠ¨å¸®ä½ ç”Ÿæˆä¸Šé¢çš„ä»£ç !\n",
        "\n",
        "    Type Hintsè§£é‡Š:\n",
        "    ---------------\n",
        "    - Path: pathlib.Pathç±»å‹(æ–‡ä»¶è·¯å¾„)\n",
        "    - str: å­—ç¬¦ä¸²ç±»å‹\n",
        "    - int: æ•´æ•°ç±»å‹\n",
        "    - FilePriority: æˆ‘ä»¬åˆšå®šä¹‰çš„æšä¸¾ç±»å‹\n",
        "\n",
        "    è¿™äº›ç±»å‹æç¤ºçš„ä½œç”¨:\n",
        "    - å‘Šè¯‰IDEè¿™æ˜¯ä»€ä¹ˆç±»å‹(ä¼šæœ‰è‡ªåŠ¨è¡¥å…¨)\n",
        "    - å‘Šè¯‰è¯»ä»£ç çš„äººè¿™ä¸ªå˜é‡åº”è¯¥æ˜¯ä»€ä¹ˆ\n",
        "    - å¯ä»¥ç”¨mypyç­‰å·¥å…·æ£€æŸ¥ç±»å‹é”™è¯¯\n",
        "    \"\"\"\n",
        "\n",
        "    # æ–‡ä»¶è·¯å¾„ (Pathç±»å‹,ä¸æ˜¯str!)\n",
        "    path: Path\n",
        "\n",
        "    # åŸå§‹æ–‡ä»¶å (ä¾‹å¦‚: \"01ç¬¬ä¸€èŠ‚[é˜²æ–­æ›´]_ç¬”è®°.pdf\")\n",
        "    original_name: str\n",
        "\n",
        "    # æ¸…æ´—åçš„æ–‡ä»¶å (ä¾‹å¦‚: \"01ç¬¬ä¸€èŠ‚\")\n",
        "    cleaned_name: str\n",
        "\n",
        "    # åºå· (ä¾‹å¦‚: 1, 2, 3...)\n",
        "    sequence: int\n",
        "\n",
        "    # åºå·å­—ç¬¦ä¸² (ä¾‹å¦‚: \"01\", \"02\", \"03\")\n",
        "    # ä¸ºä»€ä¹ˆè¦ä¿ç•™å­—ç¬¦ä¸²? å› ä¸º\"01\"å’Œ\"1\"ä¸åŒ,\"01\"ä¿ç•™äº†å‰å¯¼é›¶\n",
        "    sequence_str: str\n",
        "\n",
        "    # æ–‡ä»¶ä¼˜å…ˆçº§ (ä¾‹å¦‚: FilePriority.PDF_NOTE)\n",
        "    priority: FilePriority\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"\n",
        "        è‡ªå®šä¹‰æ‰“å°æ ¼å¼\n",
        "\n",
        "        ä¸ºä»€ä¹ˆè¦é‡å†™__repr__?\n",
        "        ç­”: é»˜è®¤çš„æ‰“å°æ ¼å¼å¤ªé•¿,ä¸æ–¹ä¾¿æŸ¥çœ‹\n",
        "\n",
        "        __repr__çš„ä½œç”¨:\n",
        "        å½“ä½ print(file_info)æ—¶,ä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•\n",
        "\n",
        "        è¿”å›å€¼ç±»å‹ -> str è¡¨ç¤º: è¿™ä¸ªæ–¹æ³•è¿”å›å­—ç¬¦ä¸²\n",
        "        \"\"\"\n",
        "        return f\"FileInfo({self.sequence_str}_{self.cleaned_name[:20]}..., priority={self.priority.name})\"\n",
        "\n",
        "# æµ‹è¯•ä¸€ä¸‹FileInfo\n",
        "test_file = FileInfo(\n",
        "    path=Path(\"/test/file.pdf\"),\n",
        "    original_name=\"01ç¬¬ä¸€èŠ‚.pdf\",\n",
        "    cleaned_name=\"01ç¬¬ä¸€èŠ‚\",\n",
        "    sequence=1,\n",
        "    sequence_str=\"01\",\n",
        "    priority=FilePriority.PDF_NOTE\n",
        ")\n",
        "\n",
        "print(\"æµ‹è¯•FileInfo:\")\n",
        "print(test_file)  # ä¼šè°ƒç”¨__repr__æ–¹æ³•\n",
        "print(f\"è®¿é—®å±æ€§: {test_file.cleaned_name}\")  # è®¿é—®cleaned_nameå±æ€§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# æ•°æ®ç»“æ„3: KnowledgeGroup - çŸ¥è¯†å—åˆ†ç»„ç±»\n",
        "# ============================================================\n",
        "\n",
        "@dataclass\n",
        "class KnowledgeGroup:\n",
        "    \"\"\"\n",
        "    çŸ¥è¯†å—åˆ†ç»„æ•°æ®ç±»\n",
        "\n",
        "    ä¸€ä¸ªçŸ¥è¯†å— = åŒä¸€ä¸ªä¸»é¢˜çš„å¤šä¸ªæ–‡ä»¶\n",
        "    ä¾‹å¦‚: \"01ç¬¬ä¸€èŠ‚ ä¸‰é©¾é©¬è½¦\" è¿™ä¸ªçŸ¥è¯†å—åŒ…å«:\n",
        "        - 01ç¬¬ä¸€èŠ‚_ç¬”è®°.pdf\n",
        "        - 01ç¬¬ä¸€èŠ‚.doc\n",
        "        - 01ç¬¬ä¸€èŠ‚.pptx\n",
        "\n",
        "    Type Hintsé«˜çº§ç”¨æ³•:\n",
        "    -------------------\n",
        "    - List[FileInfo]: è¡¨ç¤º\"FileInfoå¯¹è±¡çš„åˆ—è¡¨\"\n",
        "    - List[str]: è¡¨ç¤º\"å­—ç¬¦ä¸²çš„åˆ—è¡¨\"\n",
        "    - Dict: è¡¨ç¤º\"å­—å…¸\"\n",
        "    \"\"\"\n",
        "\n",
        "    # ç»„çš„å”¯ä¸€æ ‡è¯† (ä¾‹å¦‚: \"01_ä¸­å›½ç»æµçš„ä¸‰é©¾é©¬è½¦\")\n",
        "    group_key: str\n",
        "\n",
        "    # çŸ¥è¯†ä¸»é¢˜ (ä¾‹å¦‚: \"ä¸­å›½ç»æµçš„ä¸‰é©¾é©¬è½¦\")\n",
        "    topic: str\n",
        "\n",
        "    # åºå· (ä¾‹å¦‚: 1)\n",
        "    sequence: int\n",
        "\n",
        "    # è¯¥ç»„çš„æ‰€æœ‰æ–‡ä»¶ (List[FileInfo]è¡¨ç¤º:è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨,é‡Œé¢è£…çš„æ˜¯FileInfoå¯¹è±¡)\n",
        "    files: List[FileInfo]\n",
        "\n",
        "    # ä¸»æ–‡ä»¶ (ä¼˜å…ˆå¤„ç†çš„æ–‡ä»¶,é€šå¸¸æ˜¯PDFç¬”è®°)\n",
        "    primary_file: FileInfo\n",
        "\n",
        "    # æ–‡ä»¶ç±»å‹åˆ—è¡¨ (ä¾‹å¦‚: ['.pdf', '.doc', '.pptx'])\n",
        "    file_types: List[str]\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"\n",
        "        è½¬æ¢ä¸ºå­—å…¸(ç”¨äºJSONåºåˆ—åŒ–)\n",
        "\n",
        "        ä¸ºä»€ä¹ˆéœ€è¦to_dict?\n",
        "        ç­”: dataclasså¯¹è±¡ä¸èƒ½ç›´æ¥ä¿å­˜ä¸ºJSON,éœ€è¦å…ˆè½¬æ¢ä¸ºå­—å…¸\n",
        "\n",
        "        è¿”å›å€¼ -> Dict è¡¨ç¤º: è¿”å›å­—å…¸ç±»å‹\n",
        "\n",
        "        str(path)çš„ä½œç”¨:\n",
        "        - Pathå¯¹è±¡ä¸èƒ½ç›´æ¥åºåˆ—åŒ–ä¸ºJSON\n",
        "        - str(Path(\"/a/b.pdf\")) â†’ \"/a/b.pdf\" (è½¬æ¢ä¸ºå­—ç¬¦ä¸²)\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"group_key\": self.group_key,\n",
        "            \"topic\": self.topic,\n",
        "            \"sequence\": self.sequence,\n",
        "            \"primary_file\": str(self.primary_file.path),  # Pathè½¬å­—ç¬¦ä¸²\n",
        "            \"files\": [str(f.path) for f in self.files],   # åˆ—è¡¨æ¨å¯¼å¼\n",
        "            \"file_types\": self.file_types,\n",
        "        }\n",
        "\n",
        "# æµ‹è¯•ä¸€ä¸‹KnowledgeGroup\n",
        "test_group = KnowledgeGroup(\n",
        "    group_key=\"01_æµ‹è¯•\",\n",
        "    topic=\"æµ‹è¯•ä¸»é¢˜\",\n",
        "    sequence=1,\n",
        "    files=[test_file],  # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„test_file\n",
        "    primary_file=test_file,\n",
        "    file_types=['.pdf']\n",
        ")\n",
        "\n",
        "print(\"\\næµ‹è¯•KnowledgeGroup:\")\n",
        "print(f\"ä¸»é¢˜: {test_group.topic}\")\n",
        "print(f\"æ–‡ä»¶æ•°: {len(test_group.files)}\")\n",
        "print(f\"è½¬æ¢ä¸ºå­—å…¸:\\n{json.dumps(test_group.to_dict(), indent=2, ensure_ascii=False)}\")\n",
        "\n",
        "print(\"\\nâœ… æ•°æ®ç»“æ„å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. KnowledgeOrganizer æ ¸å¿ƒç±» - æ–¹æ³•è¯¦è§£\n",
        "\n",
        "### ç±»çš„è®¾è®¡ç†å¿µ\n",
        "\n",
        "**å•ä¸€èŒè´£åŸåˆ™ (SRP)**:\n",
        "- è¿™ä¸ªç±»åªåšä¸€ä»¶äº‹: ç»„ç»‡çŸ¥è¯†æ–‡ä»¶\n",
        "- ä¸è´Ÿè´£åŠ è½½æ–‡ä»¶å†…å®¹(é‚£æ˜¯DocumentLoaderçš„å·¥ä½œ)\n",
        "- ä¸è´Ÿè´£æå–çŸ¥è¯†(é‚£æ˜¯KnowledgeExtractorçš„å·¥ä½œ)\n",
        "\n",
        "**ç±» = å¯¹è±¡çš„æ¨¡æ¿**:\n",
        "- ç±»å®šä¹‰äº†å¯¹è±¡æœ‰å“ªäº›å±æ€§å’Œæ–¹æ³•\n",
        "- é€šè¿‡ç±»åˆ›å»ºå¯¹è±¡: `organizer = KnowledgeOrganizer(...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# KnowledgeOrganizer ç±»çš„å¼€å¤´éƒ¨åˆ†\n",
        "# ============================================================\n",
        "\n",
        "class KnowledgeOrganizer:\n",
        "    \"\"\"\n",
        "    çŸ¥è¯†æ–‡ä»¶æ™ºèƒ½ç»„ç»‡å™¨\n",
        "\n",
        "    è¿™ä¸ªç±»çš„å·¥ä½œæµç¨‹:\n",
        "    1. æ‰«æç›®å½• â†’ æ‰¾åˆ°æ‰€æœ‰pdf/doc/pptxæ–‡ä»¶\n",
        "    2. æ¸…æ´—æ–‡ä»¶å â†’ å»é™¤[é˜²æ–­æ›´]ç­‰å™ªéŸ³\n",
        "    3. æå–åºå· â†’ è¯†åˆ«01, 02ç­‰\n",
        "    4. è®¡ç®—ç›¸ä¼¼åº¦ â†’ åˆ¤æ–­å“ªäº›æ–‡ä»¶å±äºåŒä¸€çŸ¥è¯†å—\n",
        "    5. æ™ºèƒ½åˆ†ç»„ â†’ æŠŠç›¸ä¼¼çš„æ–‡ä»¶å½’ä¸ºä¸€ç»„\n",
        "    6. é€‰æ‹©ä¸»æ–‡ä»¶ â†’ æ¯ç»„é€‰ä¼˜å…ˆçº§æœ€é«˜çš„æ–‡ä»¶\n",
        "    \"\"\"\n",
        "\n",
        "    # ============================================================\n",
        "    # ç±»å±æ€§ (Class Attributes)\n",
        "    # ============================================================\n",
        "    # ç±»å±æ€§ vs å®ä¾‹å±æ€§:\n",
        "    # - ç±»å±æ€§: æ‰€æœ‰å¯¹è±¡å…±äº«,å®šä¹‰åœ¨__init__å¤–é¢\n",
        "    # - å®ä¾‹å±æ€§: æ¯ä¸ªå¯¹è±¡ç‹¬æœ‰,å®šä¹‰åœ¨__init__é‡Œé¢\n",
        "    #\n",
        "    # ä¸ºä»€ä¹ˆè¿™é‡Œç”¨ç±»å±æ€§?\n",
        "    # ç­”: æ”¯æŒçš„æ–‡ä»¶æ‰©å±•åå’Œå™ªéŸ³æ¨¡å¼å¯¹æ‰€æœ‰å¯¹è±¡éƒ½ä¸€æ ·,æ²¡å¿…è¦æ¯ä¸ªå¯¹è±¡éƒ½å¤åˆ¶ä¸€ä»½\n",
        "\n",
        "    # Set[str] è¡¨ç¤º: è¿™æ˜¯ä¸€ä¸ªé›†åˆ,é‡Œé¢è£…çš„æ˜¯å­—ç¬¦ä¸²\n",
        "    # Set vs Listçš„åŒºåˆ«:\n",
        "    # - Set: æ— åº,ä¸èƒ½é‡å¤,æŸ¥æ‰¾å¿« â†’ é€‚åˆ\"åˆ¤æ–­æŸä¸ªå…ƒç´ æ˜¯å¦å­˜åœ¨\"\n",
        "    # - List: æœ‰åº,å¯ä»¥é‡å¤,æŸ¥æ‰¾æ…¢ â†’ é€‚åˆ\"éœ€è¦é¡ºåº\"çš„åœºæ™¯\n",
        "    SUPPORTED_EXTENSIONS: Set[str] = {'.pdf', '.doc', '.docx', '.ppt', '.pptx'}\n",
        "\n",
        "    # List[str] è¡¨ç¤º: è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨,é‡Œé¢è£…çš„æ˜¯å­—ç¬¦ä¸²\n",
        "    # è¿™äº›å­—ç¬¦ä¸²æ˜¯æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼(pattern)\n",
        "    # ç”¨äºåŒ¹é…å¹¶åˆ é™¤æ–‡ä»¶åä¸­çš„å™ªéŸ³\n",
        "    NOISE_PATTERNS: List[str] = [\n",
        "        r'\\[é˜²æ–­æ›´.*?\\]',      # åŒ¹é… [é˜²æ–­æ›´å¾®coc36666]\n",
        "        r'\\[.*?å¾®.*?\\]',        # åŒ¹é… ä»»ä½•åŒ…å«\"å¾®\"çš„æ–¹æ‹¬å·\n",
        "        r'_\\d{14}',             # åŒ¹é… _20250706193405 (14ä½æ•°å­—)\n",
        "        r'_\\d{8}',              # åŒ¹é… _20250706 (8ä½æ•°å­—)\n",
        "        r'_ç¬”è®°',                # åŒ¹é… _ç¬”è®°\n",
        "        r'\\s*\\(.*?\\)\\s*',       # åŒ¹é… (ä»»ä½•æ‹¬å·å†…å®¹)\n",
        "    ]\n",
        "\n",
        "print(\"âœ… ç±»å®šä¹‰å¼€å¤´éƒ¨åˆ†å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### __init__æ–¹æ³• - åˆå§‹åŒ–\n",
        "\n",
        "**initçš„ä½œç”¨**: åˆ›å»ºå¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨,ç”¨äºåˆå§‹åŒ–å¯¹è±¡çš„å±æ€§\n",
        "\n",
        "```python\n",
        "organizer = KnowledgeOrganizer(\"/path/to/dir\")\n",
        "# ä¸Šé¢è¿™è¡Œä»£ç ä¼šè‡ªåŠ¨è°ƒç”¨__init__æ–¹æ³•\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# __init__æ–¹æ³•çš„å®Œæ•´ç¤ºä¾‹(ç‹¬ç«‹å±•ç¤º,ä¾¿äºç†è§£)\n",
        "\n",
        "def __init__(\n",
        "    self,                          # self = å¯¹è±¡æœ¬èº«(Pythonè‡ªåŠ¨ä¼ å…¥,ä¸éœ€è¦æ‰‹åŠ¨ä¼ )\n",
        "    knowledge_base_dir: str | Path,  # çŸ¥è¯†åº“ç›®å½• (stræˆ–Pathéƒ½å¯ä»¥)\n",
        "    similarity_threshold: float = 0.7,  # ç›¸ä¼¼åº¦é˜ˆå€¼,é»˜è®¤0.7\n",
        "    verbose: bool = True            # æ˜¯å¦æ‰“å°æ—¥å¿—,é»˜è®¤True\n",
        "):\n",
        "    \"\"\"\n",
        "    åˆå§‹åŒ–æ–¹æ³•\n",
        "\n",
        "    å‚æ•°è§£é‡Š:\n",
        "    -----------\n",
        "    self:\n",
        "        - å¯¹è±¡æœ¬èº«\n",
        "        - Pythonè‡ªåŠ¨ä¼ å…¥,è°ƒç”¨æ—¶ä¸éœ€è¦å†™\n",
        "        - é€šè¿‡selfè®¿é—®å¯¹è±¡çš„å±æ€§: self.xxx\n",
        "\n",
        "    knowledge_base_dir: str | Path\n",
        "        - str | Path è¡¨ç¤º: å¯ä»¥ä¼ å­—ç¬¦ä¸²æˆ–Pathå¯¹è±¡\n",
        "        - ä¾‹å¦‚: \"/path/to/dir\" æˆ– Path(\"/path/to/dir\")\n",
        "        - Python 3.10+ çš„æ–°è¯­æ³•,ä¹Ÿå¯å†™æˆ Union[str, Path]\n",
        "\n",
        "    similarity_threshold: float = 0.7\n",
        "        - = 0.7 è¡¨ç¤ºé»˜è®¤å€¼\n",
        "        - å¦‚æœä¸ä¼ è¿™ä¸ªå‚æ•°,å°±ç”¨0.7\n",
        "        - è°ƒç”¨æ—¶å¯ä»¥æ”¹: KnowledgeOrganizer(..., similarity_threshold=0.8)\n",
        "\n",
        "    verbose: bool = True\n",
        "        - bool = å¸ƒå°”ç±»å‹ (Trueæˆ–False)\n",
        "        - æ§åˆ¶æ˜¯å¦æ‰“å°æ—¥å¿—\n",
        "    \"\"\"\n",
        "\n",
        "    # ============================================================\n",
        "    # æ­¥éª¤1: ä¿å­˜å‚æ•°åˆ°å¯¹è±¡å±æ€§\n",
        "    # ============================================================\n",
        "    # self.xxx = yyy è¡¨ç¤º: æŠŠyyyä¿å­˜åˆ°å¯¹è±¡çš„xxxå±æ€§ä¸­\n",
        "    # è¿™æ ·å…¶ä»–æ–¹æ³•å°±å¯ä»¥é€šè¿‡ self.xxx è®¿é—®åˆ°è¿™ä¸ªå€¼\n",
        "\n",
        "    self.knowledge_base_dir = Path(knowledge_base_dir)  # ç»Ÿä¸€è½¬æ¢ä¸ºPathå¯¹è±¡\n",
        "    self.similarity_threshold = similarity_threshold\n",
        "    self.verbose = verbose\n",
        "\n",
        "    # ============================================================\n",
        "    # æ­¥éª¤2: éªŒè¯ç›®å½•æ˜¯å¦æœ‰æ•ˆ\n",
        "    # ============================================================\n",
        "    # é˜²å¾¡æ€§ç¼–ç¨‹: æ£€æŸ¥è¾“å…¥æ˜¯å¦åˆæ³•,å¦‚æœä¸åˆæ³•å°±æŠ¥é”™\n",
        "    # è¿™æ ·å¯ä»¥åœ¨é—®é¢˜å‘ç”Ÿæ—¶ç«‹å³å‘ç°,è€Œä¸æ˜¯ç­‰åˆ°åé¢å‡ºé”™\n",
        "\n",
        "    if not self.knowledge_base_dir.exists():\n",
        "        # .exists()æ–¹æ³•: æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
        "        # notè¡¨ç¤ºå–å: å¦‚æœä¸å­˜åœ¨,å°±æ‰§è¡Œä¸‹é¢çš„ä»£ç \n",
        "        raise ValueError(f\"ç›®å½•ä¸å­˜åœ¨: {self.knowledge_base_dir}\")\n",
        "        # raise: æŠ›å‡ºå¼‚å¸¸(æŠ¥é”™)\n",
        "        # ValueError: å€¼é”™è¯¯(å‚æ•°ä¸åˆæ³•)\n",
        "        # f-string: f\"...\" å¯ä»¥åœ¨å­—ç¬¦ä¸²ä¸­æ’å…¥å˜é‡\n",
        "\n",
        "    if not self.knowledge_base_dir.is_dir():\n",
        "        # .is_dir()æ–¹æ³•: æ£€æŸ¥è·¯å¾„æ˜¯å¦æ˜¯ç›®å½•(è€Œä¸æ˜¯æ–‡ä»¶)\n",
        "        raise ValueError(f\"ä¸æ˜¯ç›®å½•: {self.knowledge_base_dir}\")\n",
        "\n",
        "    # ============================================================\n",
        "    # æ­¥éª¤3: æ‰“å°åˆå§‹åŒ–æˆåŠŸä¿¡æ¯\n",
        "    # ============================================================\n",
        "    self._log(f\"âœ… åˆå§‹åŒ–å®Œæˆ: {self.knowledge_base_dir}\")\n",
        "    # _logæ˜¯è‡ªå®šä¹‰çš„è¾…åŠ©æ–¹æ³•(ä¸‹é¢ä¼šå®šä¹‰)\n",
        "    # æ–¹æ³•åå‰æœ‰ä¸‹åˆ’çº¿_è¡¨ç¤º: è¿™æ˜¯\"ç§æœ‰æ–¹æ³•\",ä»…ä¾›å†…éƒ¨ä½¿ç”¨\n",
        "\n",
        "print(\"âœ… __init__æ–¹æ³•è§£é‡Šå®Œæˆ\")\n",
        "\n",
        "# ============================================================\n",
        "# çŸ¥è¯†ç‚¹è¡¥å……: str | Path vs Union[str, Path]\n",
        "# ============================================================\n",
        "print(\"\\nğŸ’¡ çŸ¥è¯†ç‚¹: ç±»å‹æç¤ºçš„ä¸¤ç§å†™æ³•\")\n",
        "print(\"Python 3.10+: str | Path\")\n",
        "print(\"Python 3.9-:  Union[str, Path]\")\n",
        "print(\"ä¸¤ç§å†™æ³•åŠŸèƒ½å®Œå…¨ç›¸åŒ,æ–°è¯­æ³•æ›´ç®€æ´\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### æ ¸å¿ƒæ–¹æ³•å®ç°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Œæ•´çš„KnowledgeOrganizerç±»å®ç°(é€‚åº¦è¯¦ç»†æ³¨é‡Šç‰ˆ)\n",
        "\n",
        "class KnowledgeOrganizer:\n",
        "    \"\"\"çŸ¥è¯†æ–‡ä»¶æ™ºèƒ½ç»„ç»‡å™¨\"\"\"\n",
        "\n",
        "    SUPPORTED_EXTENSIONS: Set[str] = {'.pdf', '.doc', '.docx', '.ppt', '.pptx'}\n",
        "    NOISE_PATTERNS: List[str] = [\n",
        "        r'\\[é˜²æ–­æ›´.*?\\]', r'\\[.*?å¾®.*?\\]', r'_\\d{14}',\n",
        "        r'_\\d{8}', r'_ç¬”è®°', r'\\s*\\(.*?\\)\\s*',\n",
        "    ]\n",
        "\n",
        "    def __init__(self, knowledge_base_dir: str | Path,\n",
        "                 similarity_threshold: float = 0.7, verbose: bool = True):\n",
        "        self.knowledge_base_dir = Path(knowledge_base_dir)\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if not self.knowledge_base_dir.exists():\n",
        "            raise ValueError(f\"ç›®å½•ä¸å­˜åœ¨: {self.knowledge_base_dir}\")\n",
        "        if not self.knowledge_base_dir.is_dir():\n",
        "            raise ValueError(f\"ä¸æ˜¯ç›®å½•: {self.knowledge_base_dir}\")\n",
        "\n",
        "        self._log(f\"âœ… åˆå§‹åŒ–å®Œæˆ: {self.knowledge_base_dir}\")\n",
        "\n",
        "    def _log(self, message: str) -> None:\n",
        "        \"\"\"å†…éƒ¨æ—¥å¿—æ–¹æ³•\"\"\"\n",
        "        if self.verbose:\n",
        "            print(message)\n",
        "\n",
        "    def clean_filename(self, filename: str) -> str:\n",
        "        \"\"\"\n",
        "        æ¸…æ´—æ–‡ä»¶å,å»é™¤å™ªéŸ³\n",
        "\n",
        "        å‚æ•°: filename - åŸå§‹æ–‡ä»¶å(å«æ‰©å±•å)\n",
        "        è¿”å›: æ¸…æ´—åçš„æ–‡ä»¶å(ä¸å«æ‰©å±•å)\n",
        "\n",
        "        å¤„ç†æµç¨‹:\n",
        "        1. Path(filename).stem â†’ å»é™¤æ‰©å±•å\n",
        "        2. re.sub(pattern, '', name) â†’ åº”ç”¨æ‰€æœ‰å™ªéŸ³æ¨¡å¼\n",
        "        3. re.sub(r'\\\\s+', ' ', name).strip() â†’ æ¸…ç†ç©ºæ ¼\n",
        "        \"\"\"\n",
        "        name = Path(filename).stem\n",
        "        for pattern in self.NOISE_PATTERNS:\n",
        "            name = re.sub(pattern, '', name)\n",
        "        name = re.sub(r'\\\\s+', ' ', name).strip()\n",
        "        return name\n",
        "\n",
        "    def extract_sequence_number(self, filename: str) -> Tuple[int, str]:\n",
        "        \"\"\"\n",
        "        æå–æ–‡ä»¶åå¼€å¤´çš„åºå·\n",
        "\n",
        "        å‚æ•°: filename - æ–‡ä»¶å\n",
        "        è¿”å›: (åºå·æ•´æ•°, åºå·å­—ç¬¦ä¸²) æˆ– (999999, \"\") å¦‚æœæ²¡æœ‰åºå·\n",
        "\n",
        "        ç¤ºä¾‹: \"01ç¬¬ä¸€èŠ‚\" â†’ (1, \"01\")\n",
        "        \"\"\"\n",
        "        match = re.match(r'^(\\\\d+)', filename)\n",
        "        if match:\n",
        "            seq_str = match.group(1)\n",
        "            return (int(seq_str), seq_str)\n",
        "        return (999999, \"\")  # æ²¡æœ‰åºå·çš„æ–‡ä»¶æ’åˆ°æœ€å\n",
        "\n",
        "    def calculate_similarity(self, str1: str, str2: str) -> float:\n",
        "        \"\"\"\n",
        "        è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦\n",
        "\n",
        "        å‚æ•°: str1, str2 - ä¸¤ä¸ªå­—ç¬¦ä¸²\n",
        "        è¿”å›: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)\n",
        "\n",
        "        ç®—æ³•: difflib.SequenceMatcheråŸºäºLCS(æœ€é•¿å…¬å…±å­åºåˆ—)\n",
        "        \"\"\"\n",
        "        return SequenceMatcher(None, str1, str2).ratio()\n",
        "\n",
        "    def get_file_priority(self, file_path: Path) -> FilePriority:\n",
        "        \"\"\"\n",
        "        è·å–æ–‡ä»¶ä¼˜å…ˆçº§\n",
        "\n",
        "        è§„åˆ™:\n",
        "        - PDFç¬”è®°(æ–‡ä»¶åå«\"ç¬”è®°\") â†’ æœ€é«˜ä¼˜å…ˆçº§\n",
        "        - Wordæ–‡æ¡£ â†’ æ¬¡ä¹‹\n",
        "        - æ™®é€šPDF â†’ å†æ¬¡\n",
        "        - PPT â†’ æœ€ä½\n",
        "        \"\"\"\n",
        "        name_lower = file_path.name.lower()\n",
        "        suffix = file_path.suffix.lower()\n",
        "\n",
        "        if 'ç¬”è®°' in name_lower and suffix == '.pdf':\n",
        "            return FilePriority.PDF_NOTE\n",
        "        if suffix in ['.doc', '.docx']:\n",
        "            return FilePriority.WORD_DOC\n",
        "        if suffix == '.pdf':\n",
        "            return FilePriority.PDF_REGULAR\n",
        "        if suffix in ['.ppt', '.pptx']:\n",
        "            return FilePriority.POWERPOINT\n",
        "        return FilePriority.UNKNOWN\n",
        "\n",
        "    def create_file_info(self, file_path: Path) -> FileInfo:\n",
        "        \"\"\"åˆ›å»ºFileInfoå¯¹è±¡(æ±‡æ€»æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯)\"\"\"\n",
        "        original_name = file_path.name\n",
        "        cleaned_name = self.clean_filename(original_name)\n",
        "        sequence, sequence_str = self.extract_sequence_number(cleaned_name)\n",
        "        priority = self.get_file_priority(file_path)\n",
        "\n",
        "        return FileInfo(\n",
        "            path=file_path, original_name=original_name,\n",
        "            cleaned_name=cleaned_name, sequence=sequence,\n",
        "            sequence_str=sequence_str, priority=priority\n",
        "        )\n",
        "\n",
        "    def group_files_by_similarity(self, files: List[FileInfo]) -> Dict[str, KnowledgeGroup]:\n",
        "        \"\"\"\n",
        "        æ ¸å¿ƒç®—æ³•: æ ¹æ®ç›¸ä¼¼åº¦åˆ†ç»„æ–‡ä»¶\n",
        "\n",
        "        æµç¨‹:\n",
        "        1. éå†æ¯ä¸ªæ–‡ä»¶\n",
        "        2. æŸ¥æ‰¾ç›¸ä¼¼åº¦>=thresholdä¸”åºå·ç›¸åŒçš„æ–‡ä»¶\n",
        "        3. å½’ä¸ºä¸€ç»„\n",
        "        4. é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„ä½œä¸ºä¸»æ–‡ä»¶\n",
        "\n",
        "        æ—¶é—´å¤æ‚åº¦: O(nÂ²)\n",
        "        ç©ºé—´å¤æ‚åº¦: O(n)\n",
        "        \"\"\"\n",
        "        if not files:\n",
        "            return {}\n",
        "\n",
        "        groups: Dict[str, KnowledgeGroup] = {}\n",
        "        processed: Set[Path] = set()\n",
        "\n",
        "        for i, file1 in enumerate(files):\n",
        "            if file1.path in processed:\n",
        "                continue\n",
        "\n",
        "            group_key = f\"{file1.sequence_str}_{file1.cleaned_name[:20]}\"\n",
        "            group_files = [file1]\n",
        "            processed.add(file1.path)\n",
        "\n",
        "            # æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶\n",
        "            for file2 in files[i+1:]:\n",
        "                if file2.path in processed:\n",
        "                    continue\n",
        "\n",
        "                if file1.sequence == file2.sequence:\n",
        "                    similarity = self.calculate_similarity(\n",
        "                        file1.cleaned_name, file2.cleaned_name\n",
        "                    )\n",
        "\n",
        "                    if similarity >= self.similarity_threshold:\n",
        "                        group_files.append(file2)\n",
        "                        processed.add(file2.path)\n",
        "                        self._log(f\"  â†³ ç›¸ä¼¼åº¦={similarity:.2f}: {file2.original_name}\")\n",
        "\n",
        "            # æŒ‰ä¼˜å…ˆçº§æ’åº,é€‰ä¸»æ–‡ä»¶\n",
        "            group_files.sort(key=lambda f: (f.priority.value, f.original_name))\n",
        "            primary_file = group_files[0]\n",
        "\n",
        "            group = KnowledgeGroup(\n",
        "                group_key=group_key, topic=file1.cleaned_name,\n",
        "                sequence=file1.sequence, files=group_files,\n",
        "                primary_file=primary_file,\n",
        "                file_types=[f.path.suffix for f in group_files]\n",
        "            )\n",
        "\n",
        "            groups[group_key] = group\n",
        "            self._log(f\"âœ“ çŸ¥è¯†å—: {file1.cleaned_name} ({len(group_files)}ä¸ªæ–‡ä»¶)\")\n",
        "\n",
        "        return groups\n",
        "\n",
        "    def scan_and_organize(self) -> Dict[str, Dict[str, KnowledgeGroup]]:\n",
        "        \"\"\"\n",
        "        ä¸»æ–¹æ³•: æ‰«æå¹¶ç»„ç»‡ç›®å½•\n",
        "\n",
        "        è¿”å›: {domain_name: {group_key: KnowledgeGroup}}\n",
        "        \"\"\"\n",
        "        result: Dict[str, Dict[str, KnowledgeGroup]] = defaultdict(dict)\n",
        "\n",
        "        self._log(f\"\\\\n{'='*80}\\\\nğŸ“š å¼€å§‹æ‰«æ: {self.knowledge_base_dir}\\\\n{'='*80}\\\\n\")\n",
        "\n",
        "        # è·å–æ‰€æœ‰æ–‡ä»¶\n",
        "        all_files: List[Path] = []\n",
        "        for ext in self.SUPPORTED_EXTENSIONS:\n",
        "            all_files.extend(self.knowledge_base_dir.glob(f\"*{ext}\"))\n",
        "\n",
        "        if not all_files:\n",
        "            self._log(\"âš ï¸  æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶\")\n",
        "            return dict(result)\n",
        "\n",
        "        self._log(f\"ğŸ“‚ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶\\\\n\")\n",
        "\n",
        "        # åˆ›å»ºFileInfo â†’ åˆ†ç»„ â†’ æ’åº\n",
        "        file_infos = [self.create_file_info(f) for f in all_files]\n",
        "        groups = self.group_files_by_similarity(file_infos)\n",
        "        sorted_groups = dict(sorted(groups.items(), key=lambda x: x[1].sequence))\n",
        "\n",
        "        domain_name = self.knowledge_base_dir.name\n",
        "        result[domain_name] = sorted_groups\n",
        "\n",
        "        self._log(f\"\\\\n{'='*80}\\\\nâœ… å®Œæˆ: {len(sorted_groups)} ä¸ªçŸ¥è¯†å—\\\\n{'='*80}\\\\n\")\n",
        "\n",
        "        return dict(result)\n",
        "\n",
        "    def print_organization(self) -> Dict[str, Dict[str, KnowledgeGroup]]:\n",
        "        \"\"\"æ‰«æå¹¶æ‰“å°ç»„ç»‡ç»“æ„(ç”¨äºæ£€æŸ¥)\"\"\"\n",
        "        organized = self.scan_and_organize()\n",
        "\n",
        "        print(\"\\\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š çŸ¥è¯†åº“ç»„ç»‡ç»“æ„\")\n",
        "        print(\"=\"*80 + \"\\\\n\")\n",
        "\n",
        "        for domain, groups in organized.items():\n",
        "            print(f\"ğŸ¯ é¢†åŸŸ: {domain}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            for group_key, group in groups.items():\n",
        "                print(f\"\\\\n  ğŸ“– #{group.sequence}: {group.topic}\")\n",
        "                print(f\"     ä¸»æ–‡ä»¶: {group.primary_file.original_name}\")\n",
        "                print(f\"     ä¼˜å…ˆçº§: {group.primary_file.priority.name}\")\n",
        "                print(f\"     æ–‡ä»¶æ•°: {len(group.files)}\")\n",
        "\n",
        "                if len(group.files) > 1:\n",
        "                    print(f\"     æ‰€æœ‰æ–‡ä»¶:\")\n",
        "                    for f in group.files:\n",
        "                        print(f\"       â€¢ {f.original_name} [{f.priority.name}]\")\n",
        "\n",
        "        print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")\n",
        "        return organized\n",
        "\n",
        "    def export_to_json(self, output_path: str | Path) -> None:\n",
        "        \"\"\"å¯¼å‡ºä¸ºJSON\"\"\"\n",
        "        organized = self.scan_and_organize()\n",
        "\n",
        "        export_data = {}\n",
        "        for domain, groups in organized.items():\n",
        "            export_data[domain] = {\n",
        "                group_key: group.to_dict()\n",
        "                for group_key, group in groups.items()\n",
        "            }\n",
        "\n",
        "        output_path = Path(output_path)\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        self._log(f\"âœ… å·²å¯¼å‡ºåˆ°: {output_path}\")\n",
        "\n",
        "\n",
        "print(\"âœ… KnowledgeOrganizer ç±»å®Œæ•´å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ä½¿ç”¨ç¤ºä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆå§‹åŒ–ç»„ç»‡å™¨\n",
        "organizer = KnowledgeOrganizer(\n",
        "    knowledge_base_dir=\"/Users/zhou/Project/AnalystChain/jupyter_notebook/macroeconomic_analysis/knowledge_base\",\n",
        "    similarity_threshold=0.7,\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ‰“å°ç»„ç»‡ç»“æ„\n",
        "organized = organizer.print_organization()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. æ€»ç»“\n",
        "\n",
        "### âœ… æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
        "\n",
        "1. **Type Hints**: ç»™ä»£ç åŠ \"è¯´æ˜ä¹¦\"\n",
        "2. **dataclass**: è‡ªåŠ¨ç”Ÿæˆåˆå§‹åŒ–ä»£ç \n",
        "3. **Path**: æ™ºèƒ½æ–‡ä»¶è·¯å¾„å¤„ç†\n",
        "4. **SequenceMatcher**: å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—\n",
        "5. **æ­£åˆ™è¡¨è¾¾å¼**: æ–‡æœ¬æ¨¡å¼åŒ¹é…\n",
        "\n",
        "### ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ \n",
        "\n",
        "- **æ­¥éª¤2**: æ–‡æ¡£åŠ è½½ä¸æ¸…æ´— (DocumentLoader)\n",
        "- **æ­¥éª¤3**: LLMæå–ç»“æ„åŒ–çŸ¥è¯† (KnowledgeExtractor)\n",
        "- **æ­¥éª¤4**: å‘é‡åŒ–å­˜å‚¨ (VectorStoreManager)\n",
        "\n",
        "### ğŸ’¡ å­¦ä¹ å»ºè®®\n",
        "\n",
        "1. è¿è¡Œæ¯ä¸ªcell,çœ‹çœ‹è¾“å‡º\n",
        "2. ä¿®æ”¹å‚æ•°,è§‚å¯Ÿå˜åŒ–\n",
        "3. é‡åˆ°ä¸æ‡‚çš„API,æŸ¥å®˜æ–¹æ–‡æ¡£æˆ–é—®æˆ‘\n",
        "4. æŠ„åˆ°è‡ªå·±çš„notebook,è¾¹æŠ„è¾¹ç†è§£\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
