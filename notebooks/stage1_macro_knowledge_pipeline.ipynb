{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 阶段1：知识处理Pipeline\n",
    "\n",
    "**目标**：将非结构化文档（PDF/Word/PPT）转为结构化知识库（向量库+JSON）\n",
    "\n",
    "**方案**：向量库+JSON双存储\n",
    "\n",
    "**为什么双存储**：向量库支持语义检索，JSON支持快速精确查询\n",
    "\n",
    "**技术栈**：Qwen3-Embedding + deepseek-reasoner + Chroma\n",
    "\n",
    "**为什么这些技术**：Qwen3-Embedding中文效果好，deepseek-reasoner提取质量高，Chroma轻量级易用\n",
    "\n",
    "**前置条件**：DeepSeek API Key（在.env配置）\n",
    "\n",
    "## 流程\n",
    "\n",
    "```\n",
    "PDF/Word/PPT文件（51个）\n",
    " ↓ [模块1] KnowledgeOrganizer（扫描分组）\n",
    "17个主题组\n",
    " ↓ [模块2] DocumentLoader（加载清洗）\n",
    "List[Document]\n",
    " ↓ [模块3] KnowledgeExtractor (deepseek-reasoner)（LLM提取）\n",
    "结构化JSON\n",
    " ↓ [模块4] VectorStoreManager (Qwen3-Embedding)（向量化）\n",
    "Chroma向量库\n",
    " ↓ [模块5] KnowledgeProcessor（协调执行）\n",
    "完整知识库\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,042 - INFO - [完成] 依赖导入完成\n"
     ]
    }
   ],
   "source": [
    "# 环境准备\n",
    "\n",
    "# 标准库\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# LangChain - Document Loaders\n",
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader,           # PDF加载\n",
    "    Docx2txtLoader,          # Word加载\n",
    "    UnstructuredPowerPointLoader  # PPT加载\n",
    ")\n",
    "\n",
    "# LangChain - Core\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LangChain - Embeddings & VectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LangChain - LLM（deepseek-v3）\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# 日志\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"[完成] 依赖导入完成\")\n",
    "\n",
    "# 环境变量\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../config/.env\")\n",
    "\n",
    "# 静态变量\n",
    "from analyst_chain.knowledge.constants import (\n",
    "    EMBEDDING_MODEL,\n",
    "    KNOWLEDGE_BASE_DIR,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    STRUCTURED_JSON_DIR,\n",
    "    VECTOR_DB_DIR,\n",
    "    Domain,\n",
    "    VectorMetadataKeys,\n",
    ")\n",
    "# Schema定义\n",
    "from analyst_chain.knowledge.schemas import EXAMPLE_KNOWLEDGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数\n",
    "\n",
    "**路径配置**：知识库目录、输出目录、向量库目录\n",
    "\n",
    "**模型配置**：Embedding模型（Qwen3-Embedding）、LLM模型（deepseek-reasoner）\n",
    "\n",
    "**为什么**：统一管理路径和模型，便于修改和维护\n",
    "\n",
    "**关键步骤**：设置路径变量 → 创建输出目录 → 配置模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,062 - INFO - 原始知识: /Users/Qunying/Project/python/AnalystChain/data/raw/knowledge_base/macro_economy\n",
      "2026-01-23 18:09:51,062 - INFO - 结构化JSON: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/structured\n",
      "2026-01-23 18:09:51,063 - INFO - 向量存储: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/vector_db\n",
      "2026-01-23 18:09:51,063 - INFO - Embedding: Qwen/Qwen3-Embedding-0.6B\n",
      "2026-01-23 18:09:51,063 - INFO - LLM: deepseek-reasoner\n"
     ]
    }
   ],
   "source": [
    "# 全局配置\n",
    "\n",
    "# 模型配置\n",
    "LLM_MODEL = \"deepseek-reasoner\"\n",
    "LLM_TEMPERATURE = 0  # 确保输出稳定性\n",
    "\n",
    "# 文件分组配置（新增原始文件时，要重新检查）\n",
    "SIMILARITY_THRESHOLD = 0.65  # 文件名相似度阈值（同主题文件未被正确分组时，要重新设置）\n",
    "GROUP_KEY_NAME_LENGTH = 30   # group_key文件名截断长度（文件名超过30字符时，要重新设置）\n",
    "\n",
    "# 文本分割配置（新增原始文件时，要重新检查）\n",
    "CHUNK_SIZE = 800         # 分块大小（新增领域文档平均长度，与1200-1600字符相差较多时，要重新设置）\n",
    "CHUNK_OVERLAP = 100      # 重叠大小（LangChain标准10-15%。CHUNK_SIZE重新设置时，要重新计算）\n",
    "\n",
    "# LLM提取配置（新增原始文件时，要重新检查）\n",
    "EXTRACT_MAX_PAGES = 10      # 结构化提取的最大页数\n",
    "EXTRACT_MAX_CHARS = 30000   # 结构化提取的最大字符数（保持 EXTRACT_MAX_CHARS = EXTRACT_MAX_PAGES × 3000字符/页）\n",
    "\n",
    "# 当前处理领域\n",
    "CURRENT_DOMAIN = Domain.MACRO_ECONOMY\n",
    "\n",
    "# 创建输出目录（通用目录会在运行时自动创建子目录）\n",
    "PROCESSED_DATA_DIR.mkdir(exist_ok=True)\n",
    "STRUCTURED_JSON_DIR.mkdir(exist_ok=True)\n",
    "VECTOR_DB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 路径配置\n",
    "logger.info(f\"原始知识: {KNOWLEDGE_BASE_DIR / CURRENT_DOMAIN}\")\n",
    "logger.info(f\"结构化JSON: {STRUCTURED_JSON_DIR}\")\n",
    "logger.info(f\"向量存储: {VECTOR_DB_DIR}\")\n",
    "\n",
    "# 模型配置\n",
    "logger.info(f\"Embedding: {EMBEDDING_MODEL}\")\n",
    "logger.info(f\"LLM: {LLM_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据结构定义\n",
    "\n",
    "**FilePriority**：文件优先级枚举（PDF笔记>Word>PDF>PPT）\n",
    "\n",
    "**为什么这个优先级**：PDF笔记最详细完整，Word格式规范，普通PDF信息完整但不如笔记，PPT信息密度低多为摘要\n",
    "\n",
    "**FileInfo**：文件信息数据类（路径、名称、序号、优先级）\n",
    "\n",
    "**为什么这样设计**：统一管理文件信息，便于按序号分组、按优先级排序、按相似度匹配\n",
    "\n",
    "**KnowledgeGroup**：知识组数据类（主题、文件列表、代表文件）\n",
    "\n",
    "**为什么这样设计**：同主题的不同文件类型（PDF/Word/PPT）需要归为一组，便于统一处理和选择最佳文件\n",
    "\n",
    "**关键步骤**：定义枚举 → 定义数据类 → 使用dataclass装饰器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,070 - INFO - [完成] 数据结构定义完成\n"
     ]
    }
   ],
   "source": [
    "# 数据结构定义\n",
    "\n",
    "from enum import IntEnum\n",
    "\n",
    "class FilePriority(IntEnum):\n",
    "    \"\"\"文件优先级枚举\n",
    "\n",
    "    优先级规则：\n",
    "    - PDF笔记最优先（最详细完整，包含完整知识点）\n",
    "    - Word文档次之（格式规范，信息完整）\n",
    "    - 普通PDF第三（信息完整但不如笔记）\n",
    "    - PPT最后（信息密度低，多为摘要）\n",
    "    \"\"\"\n",
    "    PDF_NOTE = 1      # PDF笔记文件（文件名包含\"笔记\"）\n",
    "    WORD_DOC = 2      # Word文档\n",
    "    PDF_REGULAR = 3   # 普通PDF文件\n",
    "    POWERPOINT = 4    # PowerPoint文件\n",
    "    UNKNOWN = 99      # 未知类型\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FileInfo:\n",
    "    \"\"\"文件信息数据类\n",
    "\n",
    "    统一管理文件信息，便于按序号分组、按优先级排序、按相似度匹配。\n",
    "\n",
    "    Attributes:\n",
    "        path: 文件完整路径\n",
    "        original_name: 原始文件名\n",
    "        cleaned_name: 清洗后的文件名（去除噪音）\n",
    "        sequence: 序号（整数，用于分组）\n",
    "        sequence_str: 序号字符串（用于显示）\n",
    "        priority: 文件优先级（用于排序和选择最佳文件）\n",
    "    \"\"\"\n",
    "    path: Path\n",
    "    original_name: str\n",
    "    cleaned_name: str\n",
    "    sequence: int\n",
    "    sequence_str: str\n",
    "    priority: FilePriority\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class KnowledgeGroup:\n",
    "    \"\"\"知识组数据类\n",
    "\n",
    "    同主题的不同文件类型（PDF/Word/PPT）归为一组，便于统一处理和选择最佳文件。\n",
    "\n",
    "    Attributes:\n",
    "        group_key: 组唯一标识\n",
    "        topic: 主题名称\n",
    "        sequence: 主题序号（用于排序）\n",
    "        files: 组内所有文件（同主题的不同格式）\n",
    "        primary_file: 主要文件（优先级最高，用于代表该组）\n",
    "        file_types: 文件类型列表（用于统计）\n",
    "    \"\"\"\n",
    "    group_key: str\n",
    "    topic: str\n",
    "    sequence: int\n",
    "    files: List[FileInfo]\n",
    "    primary_file: FileInfo\n",
    "    file_types: List[str]\n",
    "\n",
    "\n",
    "logger.info(\"[完成] 数据结构定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1: KnowledgeOrganizer - 文件扫描分组\n",
    "\n",
    "**作用**：扫描知识库目录，按相似度智能分组文件\n",
    "\n",
    "**为什么**：同主题的不同文件类型（PDF/Word/PPT）需要归为一组，便于统一处理\n",
    "\n",
    "**关键步骤**：提取序号 → 计算相似度 → 按优先级排序 → 分组\n",
    "\n",
    "**输出**：17个主题组（每个组包含相关文件）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,084 - INFO - [完成] 步骤1: KnowledgeOrganizer\n"
     ]
    }
   ],
   "source": [
    "class KnowledgeOrganizer:\n",
    "    \"\"\"知识文件扫描和智能分组\n",
    "\n",
    "    功能:\n",
    "    1. 扫描知识库目录,支持PDF/Word/PPT\n",
    "    2. 清洗文件名(去除时间戳、噪音标记等)\n",
    "    3. 按相似度智能分组(同主题的不同文件类型)\n",
    "    4. 按优先级排序(PDF笔记 > Word > PDF > PPT)\n",
    "\n",
    "    分组算法:\n",
    "    - 提取序号(如\"01第一节\")作为主键\n",
    "    - 计算文件名相似度\n",
    "    - 相似度超过阈值的归为一组\n",
    "    \"\"\"\n",
    "\n",
    "    # 支持的文件扩展名\n",
    "    SUPPORTED_EXTENSIONS = {\".pdf\", \".doc\", \".docx\", \".ppt\", \".pptx\"}\n",
    "\n",
    "    # 文件名噪音模式（正则表达式）\n",
    "    NOISE_PATTERNS = [\n",
    "        r\"\\[防断更.*?\\]\",  # [防断更微coc36666]\n",
    "        r\"\\[.*?微.*?\\]\",   # [微信号xxx]\n",
    "        r\"_\\d{14}\",        # _20250706193405\n",
    "        r\"_\\d{8}\",         # _20250706\n",
    "        r\"_笔记\",          # _笔记\n",
    "        r\"\\s*\\(.*?\\)\\s*\"   # （备注）\n",
    "    ]\n",
    "\n",
    "    def __init__(self,\n",
    "                 knowledge_base_dir: str,\n",
    "                 similarity_threshold: float = SIMILARITY_THRESHOLD,\n",
    "                 group_key_name_length: int = GROUP_KEY_NAME_LENGTH,\n",
    "                 verbose: bool = True):\n",
    "        \"\"\"初始化知识组织器\n",
    "\n",
    "        Args:\n",
    "            knowledge_base_dir: 知识库根目录\n",
    "            similarity_threshold: 文件名相似度阈值（0-1），默认使用全局配置\n",
    "            group_key_name_length: group_key文件名截断长度，默认使用全局配置\n",
    "            verbose: 是否打印详细日志\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 目录不存在时抛出\n",
    "        \"\"\"\n",
    "        self.knowledge_base_dir = Path(knowledge_base_dir)\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.group_key_name_length = group_key_name_length\n",
    "        self.verbose = verbose\n",
    "        if not self.knowledge_base_dir.exists():\n",
    "            raise ValueError(f\"原始知识库目录不存在: {self.knowledge_base_dir}\")\n",
    "\n",
    "    def _log(self, msg):\n",
    "        if self.verbose: logger.info(msg)\n",
    "\n",
    "    def clean_filename(self, filename: str) -> str:\n",
    "        \"\"\"清洗文件名，去除时间戳和噪音标记\n",
    "\n",
    "        Args:\n",
    "            filename: 原始文件名（含扩展名）\n",
    "\n",
    "        Returns:\n",
    "            清洗后的文件名（不含扩展名）\n",
    "\n",
    "        Example:\n",
    "            >>> clean_filename(\"01报告_20231201[防断更].pdf\")\n",
    "            \"01报告\"\n",
    "        \"\"\"\n",
    "        name = Path(filename).stem\n",
    "        for pattern in self.NOISE_PATTERNS:\n",
    "            name = re.sub(pattern, \"\", name)\n",
    "        return re.sub(r\"\\s+\", \" \", name).strip()\n",
    "\n",
    "    def extract_sequence_number(self, filename: str) -> Tuple[int, str]:\n",
    "        \"\"\"提取文件名开头的序号\n",
    "\n",
    "        Args:\n",
    "            filename: 文件名\n",
    "\n",
    "        Returns:\n",
    "            （序号整数，序号字符串），如（1，\"01\"）或（999999，\"\"）表示无序号\n",
    "\n",
    "        Example:\n",
    "            >>> extract_sequence_number(\"01报告\")\n",
    "            (1, \"01\")\n",
    "        \"\"\"\n",
    "        match = re.match(r\"^(\\d+)\", filename)\n",
    "        return (int(match.group(1)), match.group(1)) if match else (999999, \"\")\n",
    "\n",
    "    def calculate_similarity(self, str1: str, str2: str) -> float:\n",
    "        \"\"\"计算两个字符串的相似度\n",
    "\n",
    "        Args:\n",
    "            str1: 字符串1\n",
    "            str2: 字符串2\n",
    "\n",
    "        Returns:\n",
    "            相似度分数（0-1），1表示完全相同\n",
    "        \"\"\"\n",
    "        return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "    def get_file_priority(self, file_path: Path) -> FilePriority:\n",
    "        \"\"\"根据文件类型和名称确定优先级\n",
    "\n",
    "        Args:\n",
    "            file_path: 文件路径对象\n",
    "\n",
    "        Returns:\n",
    "            FilePriority枚举值\n",
    "\n",
    "        Note:\n",
    "            优先级：PDF笔记 > Word > 普通PDF > PPT > 未知\n",
    "        \"\"\"\n",
    "        name, suffix = file_path.name.lower(), file_path.suffix.lower()\n",
    "        if \"笔记\" in name and suffix == \".pdf\": return FilePriority.PDF_NOTE\n",
    "        if suffix == \".pdf\": return FilePriority.PDF_REGULAR\n",
    "        if suffix in [\".doc\", \".docx\"]: return FilePriority.WORD_DOC\n",
    "        if suffix in [\".ppt\", \".pptx\"]: return FilePriority.POWERPOINT\n",
    "        return FilePriority.UNKNOWN\n",
    "\n",
    "    def create_file_info(self, file_path: Path) -> FileInfo:\n",
    "        \"\"\"为单个文件创建信息对象\n",
    "\n",
    "        Args:\n",
    "            file_path: 文件路径\n",
    "\n",
    "        Returns:\n",
    "            FileInfo对象，包含原始名、清洗名、序号、优先级等\n",
    "        \"\"\"\n",
    "        original_name = file_path.name\n",
    "        cleaned_name = self.clean_filename(original_name)\n",
    "        sequence, sequence_str = self.extract_sequence_number(cleaned_name)\n",
    "        priority = self.get_file_priority(file_path)\n",
    "        return FileInfo(file_path, original_name, cleaned_name, sequence, sequence_str, priority)\n",
    "\n",
    "    def group_files_by_similarity(self, files: List[FileInfo]) -> Dict[str, KnowledgeGroup]:\n",
    "        \"\"\"按序号和相似度智能分组文件\n",
    "\n",
    "        Args:\n",
    "            files: FileInfo对象列表\n",
    "\n",
    "        Returns:\n",
    "            字典{group_key: KnowledgeGroup}，每组包含相似的文件\n",
    "\n",
    "        Note:\n",
    "            同序号且相似度>=threshold的文件归为一组\n",
    "        \"\"\"\n",
    "        groups, processed = {}, set()\n",
    "        for i, file1 in enumerate(files):\n",
    "            if file1.path in processed: continue\n",
    "            group_key = f\"{file1.sequence_str}_{file1.cleaned_name[:self.group_key_name_length]}\"\n",
    "            group_files = [file1]\n",
    "            processed.add(file1.path)\n",
    "\n",
    "            for file2 in files[i+1:]:\n",
    "                if file2.path in processed: continue\n",
    "                if file1.sequence == file2.sequence:\n",
    "                    if self.calculate_similarity(file1.cleaned_name, file2.cleaned_name) >= self.similarity_threshold:\n",
    "                        group_files.append(file2)\n",
    "                        processed.add(file2.path)\n",
    "\n",
    "            group_files.sort(key=lambda f: (f.priority.value, f.original_name))\n",
    "            groups[group_key] = KnowledgeGroup(group_key, file1.cleaned_name, file1.sequence,\n",
    "                                              group_files, group_files[0], [f.path.suffix for f in group_files])\n",
    "            self._log(f\"[完成] {file1.cleaned_name[:30]} ({len(group_files)}文件)\")\n",
    "        return groups\n",
    "\n",
    "    def scan_and_organize(self) -> Dict[str, Dict[str, KnowledgeGroup]]:\n",
    "        \"\"\"扫描知识库目录并智能分组\n",
    "\n",
    "        Returns:\n",
    "            字典{domain: {group_key: KnowledgeGroup}}\n",
    "\n",
    "        Example:\n",
    "            >>> result = organizer.scan_and_organize()\n",
    "            >>> # {\"macro_economy\": {\"01_中国经济\": KnowledgeGroup(...)}}\n",
    "        \"\"\"\n",
    "        self._log(f\"扫描目录: {self.knowledge_base_dir}\")\n",
    "        all_files = []\n",
    "        for ext in self.SUPPORTED_EXTENSIONS:\n",
    "            all_files.extend(self.knowledge_base_dir.glob(f\"*{ext}\"))\n",
    "\n",
    "        if not all_files:\n",
    "            self._log(\"[警告] 未找到文件\")\n",
    "            return {}\n",
    "\n",
    "        self._log(f\"找到 {len(all_files)} 个文件\")\n",
    "        file_infos = [self.create_file_info(f) for f in all_files]\n",
    "        groups = self.group_files_by_similarity(file_infos)\n",
    "        sorted_groups = dict(sorted(groups.items(), key=lambda x: x[1].sequence))\n",
    "        self._log(f\"[完成] {len(sorted_groups)} 个知识块\\n\")\n",
    "        return {self.knowledge_base_dir.name: sorted_groups}\n",
    "\n",
    "logger.info(\"[完成] 步骤1: KnowledgeOrganizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2: DocumentLoader - 文档加载清洗\n",
    "\n",
    "**作用**：加载PDF/Word/PPT文件，清洗文本内容\n",
    "\n",
    "**为什么**：不同格式需要不同加载器，清洗去除噪音提高质量\n",
    "\n",
    "**关键步骤**：选择加载器 → 加载文档 → 清洗文本（去除特殊字符、多余空白）\n",
    "\n",
    "**输出**：LangChain Document列表（每页一个Document）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,093 - INFO - [完成] 步骤2: DocumentLoader\n"
     ]
    }
   ],
   "source": [
    "class DocumentLoader:\n",
    "    \"\"\"文档加载器\n",
    "\n",
    "    支持多种文档格式加载：\n",
    "    - PDF: PyMuPDFLoader（推荐，性能最佳）\n",
    "    - Word: Docx2txtLoader（.doc，.docx）\n",
    "    - PowerPoint: UnstructuredPowerPointLoader（.ppt，.pptx）\n",
    "    \"\"\"\n",
    "\n",
    "    def load_pdf(self, file_path: Path) -> List[Document]:\n",
    "        \"\"\"加载PDF文件\n",
    "\n",
    "        Args:\n",
    "            file_path: PDF文件路径\n",
    "\n",
    "        Returns:\n",
    "            文档列表（每页一个Document）\n",
    "        \"\"\"\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            return loader.load()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"PDF加载失败 {file_path.name}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_word(self, file_path: Path) -> List[Document]:\n",
    "        \"\"\"加载Word文件\n",
    "\n",
    "        Args:\n",
    "            file_path: Word文件路径\n",
    "\n",
    "        Returns:\n",
    "            文档列表\n",
    "        \"\"\"\n",
    "        try:\n",
    "            loader = Docx2txtLoader(str(file_path))\n",
    "            return loader.load()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Word加载失败 {file_path.name}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_ppt(self, file_path: Path) -> List[Document]:\n",
    "        \"\"\"加载PowerPoint文件\n",
    "\n",
    "        Args:\n",
    "            file_path: PPT文件路径\n",
    "\n",
    "        Returns:\n",
    "            文档列表\n",
    "        \"\"\"\n",
    "        try:\n",
    "            loader = UnstructuredPowerPointLoader(str(file_path))\n",
    "            return loader.load()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"PPT加载失败 {file_path.name}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def clean_document_text(self, doc: Document) -> Document:\n",
    "        \"\"\"清洗文档文本\n",
    "\n",
    "        清理内容：\n",
    "        - 特殊字符\n",
    "        - 多余空白\n",
    "        - 噪音内容\n",
    "\n",
    "        Args:\n",
    "            doc: 原始文档\n",
    "\n",
    "        Returns:\n",
    "            清洗后的文档\n",
    "        \"\"\"\n",
    "        text = doc.page_content\n",
    "        text = re.sub(r\"[\\uf06c\\uf0fc]\", \"\", text)  # 特殊字符\n",
    "        text = re.sub(r\"\\s+\", \" \", text)  # 多余空白\n",
    "        doc.page_content = text.strip()\n",
    "        return doc\n",
    "\n",
    "    def load_and_clean(self, file_path: Path) -> List[Document]:\n",
    "        \"\"\"加载并清洗文档（统一入口）\n",
    "\n",
    "        Args:\n",
    "            file_path: 文件路径\n",
    "\n",
    "        Returns:\n",
    "            清洗后的文档列表\n",
    "        \"\"\"\n",
    "        suffix = file_path.suffix.lower()\n",
    "\n",
    "        # 根据文件类型选择加载器\n",
    "        if suffix == \".pdf\":\n",
    "            docs = self.load_pdf(file_path)\n",
    "        elif suffix in [\".doc\", \".docx\"]:\n",
    "            docs = self.load_word(file_path)\n",
    "        elif suffix in [\".ppt\", \".pptx\"]:\n",
    "            docs = self.load_ppt(file_path)\n",
    "        else:\n",
    "            logger.warning(f\"不支持的文件类型: {suffix}\")\n",
    "            return []\n",
    "\n",
    "        # 清洗文档\n",
    "        if docs:\n",
    "            docs = [self.clean_document_text(doc) for doc in docs]\n",
    "            logger.info(f\"加载 {file_path.name}：{len(docs)}页\")\n",
    "\n",
    "        return docs\n",
    "\n",
    "logger.info(\"[完成] 步骤2: DocumentLoader\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3: KnowledgeExtractor - LLM结构化提取\n",
    "\n",
    "**作用**：使用deepseek-reasoner提取结构化知识（关键概念、指标、摘要）\n",
    "\n",
    "**为什么**：LLM能理解语义，将非结构化文档转为结构化JSON，便于查询\n",
    "\n",
    "**为什么JSON结构这样设计**：\n",
    "- `topic`：主题名称，便于识别和分类\n",
    "- `key_concepts`：核心概念（名称+定义+重要性），便于快速理解\n",
    "- `indicators`：关键指标（名称+计算+解读），便于数据分析\n",
    "- `analysis_methods`：分析方法（名称+步骤+应用），便于实际应用\n",
    "- `summary`：总结，便于快速了解全貌\n",
    "\n",
    "**关键步骤**：构建prompt → 调用LLM → 解析JSON → 保存文件\n",
    "\n",
    "**输出**：JSON格式的结构化知识文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,101 - INFO - [完成] 步骤3: KnowledgeExtractor\n"
     ]
    }
   ],
   "source": [
    "class KnowledgeExtractor:\n",
    "    \"\"\"LLM知识提取器\n",
    "\n",
    "    使用LLM从文档中提取结构化知识（JSON格式）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = LLM_MODEL, temperature: float = LLM_TEMPERATURE):\n",
    "        \"\"\"初始化知识提取器\n",
    "\n",
    "        Args:\n",
    "            model_name: LLM模型名称，默认使用全局配置\n",
    "            temperature: 温度参数，默认0确保输出稳定性\n",
    "        \"\"\"\n",
    "        example_json = json.dumps(EXAMPLE_KNOWLEDGE.model_dump(), ensure_ascii=False, indent=2)\n",
    "        self.llm = ChatDeepSeek(model=model_name, temperature=temperature)\n",
    "        logger.info(f\"LLM初始化: {model_name}\")\n",
    "        self.prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "你是金融知识提取专家。从文档提取结构化知识，返回JSON。\n",
    "\n",
    "文档：{{content}}\n",
    "\n",
    "参考格式：\n",
    "{example_json}\n",
    "\n",
    "只返回JSON。\"\"\")\n",
    "\n",
    "    def extract_from_documents(self, docs: List[Document], topic: str) -> Dict:\n",
    "        \"\"\"从文档列表提取结构化知识\n",
    "\n",
    "        Args:\n",
    "            docs: LangChain Document列表\n",
    "            topic: 知识主题\n",
    "\n",
    "        Returns:\n",
    "            结构化知识字典，包含topic/key_concepts/indicators/analysis_methods/summary\n",
    "\n",
    "        Note:\n",
    "            - 只使用前10页内容（避免token超限）\n",
    "            - 截断到30000字符\n",
    "            - 失败时返回空结构\n",
    "\n",
    "        Example:\n",
    "            >>> knowledge = extractor.extract_from_documents(docs, \"GDP分析\")\n",
    "            >>> knowledge[\"topic\"]\n",
    "            \"GDP分析\"\n",
    "        \"\"\"\n",
    "        content = \"\\n\\n\".join([d.page_content for d in docs[:EXTRACT_MAX_PAGES]])[:EXTRACT_MAX_CHARS]\n",
    "        try:\n",
    "            chain = self.prompt | self.llm | JsonOutputParser()\n",
    "            result = chain.invoke({\"content\": content})\n",
    "            result[\"topic\"] = topic\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"[KnowledgeExtractor] LLM提取失败: {e}\")\n",
    "            return {\"topic\": topic, \"key_concepts\": [], \"indicators\": [],\n",
    "                   \"analysis_methods\": [], \"summary\": \"提取失败\"}\n",
    "\n",
    "logger.info(\"[完成] 步骤3: KnowledgeExtractor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4: VectorStoreManager - 向量化存储\n",
    "\n",
    "**作用**：将文档分块并向量化，存储到Chroma向量库\n",
    "\n",
    "**为什么**：向量化支持语义检索，分块避免token超限，Chroma轻量级易用\n",
    "\n",
    "**关键步骤**：文档分块 → 向量化 → 添加元数据 → 存储到Chroma\n",
    "\n",
    "**输出**：Chroma向量数据库（支持语义检索）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,115 - INFO - [完成] 步骤4: VectorStoreManager\n"
     ]
    }
   ],
   "source": [
    "class VectorStoreManager:\n",
    "    \"\"\"向量存储管理器\n",
    "\n",
    "    负责文档向量化和Chroma向量数据库管理\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embedding_model: str,\n",
    "                 persist_directory: str):\n",
    "        \"\"\"初始化向量存储管理器\n",
    "\n",
    "        Args:\n",
    "            embedding_model: Embedding模型名称\n",
    "            persist_directory: 向量数据库持久化目录（已包含domain的完整路径）\n",
    "        \"\"\"\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.persist_directory = Path(persist_directory)\n",
    "        self.persist_directory.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(f\"Embedding初始化: {embedding_model}\")\n",
    "\n",
    "        # 初始化时创建向量存储（路径已在调用方拼装完成）\n",
    "        self.vector_store = Chroma(\n",
    "            collection_name=\"knowledge\",\n",
    "            embedding_function=self.embeddings,\n",
    "            persist_directory=str(self.persist_directory)\n",
    "        )\n",
    "\n",
    "    def split_documents(self, docs: List[Document]) -> List[Document]:\n",
    "        \"\"\"将长文档分割为小chunks\n",
    "\n",
    "        Args:\n",
    "            docs: Document列表\n",
    "\n",
    "        Returns:\n",
    "            分割后的Document列表\n",
    "\n",
    "        Note:\n",
    "            chunk_size=800，overlap=100（按全局配置）\n",
    "        \"\"\"\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, add_start_index=True\n",
    "        )\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "    def add_documents(self, docs: List[Document], metadata: Dict = None):\n",
    "        \"\"\"向量化文档并添加到存储\n",
    "\n",
    "        Args:\n",
    "            docs: Document列表\n",
    "            metadata: 附加到每个chunk的元数据（可选）\n",
    "\n",
    "        Note:\n",
    "            - 自动分割文档为chunks\n",
    "            - 附加metadata到每个chunk\n",
    "            - 持久化到Chroma\n",
    "        \"\"\"\n",
    "        if not docs:\n",
    "            logger.warning(\"[VectorStoreManager] 无文档，跳过向量化\")\n",
    "            return\n",
    "\n",
    "        chunks = self.split_documents(docs)\n",
    "        if metadata:\n",
    "            for chunk in chunks:\n",
    "                chunk.metadata.update(metadata)\n",
    "\n",
    "        self.vector_store.add_documents(chunks)\n",
    "        print(f\"[进度] 向量化: {len(chunks)} chunks\", flush=True)\n",
    "\n",
    "logger.info(\"[完成] 步骤4: VectorStoreManager\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5: KnowledgeProcessor - 完整Pipeline协调器\n",
    "\n",
    "**作用**：协调所有模块，执行完整的知识处理流程\n",
    "\n",
    "**为什么**：统一入口管理整个流程，确保各模块按顺序执行\n",
    "\n",
    "**关键步骤**：扫描分组 → 加载文档 → 提取知识 → 向量化存储 → 保存JSON\n",
    "\n",
    "**输出**：结构化JSON + 向量数据库（双存储）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,124 - INFO - [完成] 步骤5: KnowledgeProcessor\n"
     ]
    }
   ],
   "source": [
    "class KnowledgeProcessor:\n",
    "    \"\"\"知识处理Pipeline协调器\n",
    "\n",
    "    整合5个核心模块，执行完整的知识处理流程：\n",
    "    1. 文件扫描分组（KnowledgeOrganizer）\n",
    "    2. 文档加载（DocumentLoader）\n",
    "    3. 知识提取（KnowledgeExtractor）\n",
    "    4. 向量化存储（VectorStoreManager）\n",
    "    5. JSON存储\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 domain: str,\n",
    "                 knowledge_base_dir: str,\n",
    "                 memories_dir: str,\n",
    "                 vector_db_dir: str,\n",
    "                 embedding_model: str):\n",
    "        \"\"\"初始化Pipeline协调器\n",
    "\n",
    "        Args:\n",
    "            domain: 领域名称\n",
    "            knowledge_base_dir: 知识库根目录\n",
    "            memories_dir: JSON结构化知识存储目录\n",
    "            vector_db_dir: 向量数据库存储目录\n",
    "            embedding_model: Embedding模型名称\n",
    "        \"\"\"\n",
    "        # 在__init__中完成所有路径拼装（核心原则）\n",
    "        self.domain = domain\n",
    "        self.domain_knowledge_base_dir = Path(knowledge_base_dir) / domain\n",
    "        self.domain_memories_dir = Path(memories_dir) / domain\n",
    "        self.domain_vector_dir = Path(vector_db_dir) / domain\n",
    "\n",
    "        # 确保输出目录存在\n",
    "        self.domain_memories_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 初始化子组件（传递已拼装的完整路径）\n",
    "        self.organizer = KnowledgeOrganizer(str(self.domain_knowledge_base_dir))\n",
    "        self.loader = DocumentLoader()\n",
    "        self.extractor = KnowledgeExtractor()\n",
    "        self.vector_manager = VectorStoreManager(\n",
    "            embedding_model=embedding_model,\n",
    "            persist_directory=str(self.domain_vector_dir)\n",
    "        )\n",
    "        logger.info(f\"Pipeline协调器初始化完成，领域: {domain}\")\n",
    "\n",
    "    def save_to_memories(self, group_key: str, knowledge: Dict):\n",
    "        \"\"\"将结构化知识保存为JSON文件\n",
    "\n",
    "        Args:\n",
    "            group_key: 知识组唯一键\n",
    "            knowledge: 结构化知识字典\n",
    "\n",
    "        Note:\n",
    "            保存路径：domain_memories_dir/group_key.json\n",
    "        \"\"\"\n",
    "        json_file = self.domain_memories_dir / f\"{group_key}.json\"\n",
    "        with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(knowledge, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"[进度] JSON: {json_file.name}\", flush=True)\n",
    "\n",
    "    def process_all(self, limit: int = None):\n",
    "        \"\"\"执行完整Pipeline处理所有知识文件\n",
    "\n",
    "        Args:\n",
    "            limit: 限制处理数量（可选，用于测试）\n",
    "\n",
    "        Note:\n",
    "            处理流程：\n",
    "            1. 扫描分组（KnowledgeOrganizer）\n",
    "            2. 加载清洗（DocumentLoader）\n",
    "            3. 知识提取（KnowledgeExtractor）\n",
    "            4. 向量化存储（VectorStoreManager）\n",
    "            5. JSON保存\n",
    "\n",
    "        Example:\n",
    "            >>> processor.process_all(limit=2)  # 测试：只处理前2个\n",
    "            >>> processor.process_all()  # 正式：处理所有\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"开始完整Pipeline，领域: {self.domain}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        organized = self.organizer.scan_and_organize()\n",
    "\n",
    "        for domain, groups in organized.items():\n",
    "            total = len(groups) if not limit else min(limit, len(groups))\n",
    "            print(f\"\\n领域: {domain} (共{total}个知识块)\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "            count = 0\n",
    "            for group_key, group in groups.items():\n",
    "                if limit and count >= limit:\n",
    "                    print(f\"\\n达到限制({limit})，停止\")\n",
    "                    break\n",
    "\n",
    "                # 实时进度显示\n",
    "                print(f\"[进度] {count+1}/{total} {group.topic}\", flush=True)\n",
    "\n",
    "                # 加载所有文件\n",
    "                all_docs = []\n",
    "                for file_info in group.files:\n",
    "                    docs = self.loader.load_and_clean(file_info.path)\n",
    "                    if docs:\n",
    "                        all_docs.extend(docs)\n",
    "                        print(f\"[进度] 加载 {file_info.path.suffix}: {len(docs)} 页\", flush=True)\n",
    "\n",
    "                if not all_docs:\n",
    "                    logger.warning(\"[DocumentLoader] 所有文件加载失败\")\n",
    "                    continue\n",
    "                print(f\"[进度] 总计: {len(all_docs)} 页\", flush=True)\n",
    "\n",
    "                # 提取\n",
    "                knowledge = self.extractor.extract_from_documents(all_docs, group.topic)\n",
    "                self.save_to_memories(group_key, knowledge)\n",
    "\n",
    "                # 向量化（metadata使用self.domain）\n",
    "                self.vector_manager.add_documents(all_docs, {\n",
    "                    VectorMetadataKeys.DOMAIN: self.domain,\n",
    "                    VectorMetadataKeys.TOPIC: group.topic,\n",
    "                    VectorMetadataKeys.SEQUENCE: group.sequence,\n",
    "                })\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            print(f\"\\n[完成] {domain}: {count}/{total} 个\")\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"[完成] Pipeline执行完成\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\n输出目录:\")\n",
    "        print(f\"  - JSON: {self.domain_memories_dir}\")\n",
    "        print(f\"  - 向量库: {self.vector_manager.persist_directory}\")\n",
    "\n",
    "logger.info(\"[完成] 步骤5: KnowledgeProcessor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:09:51,511 - INFO - LLM初始化: deepseek-reasoner\n",
      "2026-01-23 18:09:53,801 - INFO - Use pytorch device_name: mps\n",
      "2026-01-23 18:09:53,801 - INFO - Load pretrained SentenceTransformer: Qwen/Qwen3-Embedding-0.6B\n",
      "2026-01-23 18:17:36,981 - INFO - 1 prompt is loaded, with the key: query\n",
      "2026-01-23 18:17:36,983 - INFO - Embedding初始化: Qwen/Qwen3-Embedding-0.6B\n",
      "2026-01-23 18:17:37,007 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2026-01-23 18:17:37,553 - INFO - Pipeline协调器初始化完成，领域: macro_economy\n",
      "2026-01-23 18:17:37,553 - INFO - Pipeline初始化完成\n"
     ]
    }
   ],
   "source": [
    "# Pipeline测试\n",
    "\n",
    "# 初始化Processor\n",
    "processor = KnowledgeProcessor(\n",
    "    domain=CURRENT_DOMAIN,\n",
    "    knowledge_base_dir=str(KNOWLEDGE_BASE_DIR),\n",
    "    memories_dir=str(STRUCTURED_JSON_DIR),\n",
    "    vector_db_dir=str(VECTOR_DB_DIR),\n",
    "    embedding_model=EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "logger.info(\"Pipeline初始化完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:17:37,559 - INFO - 扫描目录: /Users/Qunying/Project/python/AnalystChain/data/raw/knowledge_base/macro_economy\n",
      "2026-01-23 18:17:37,562 - INFO - 找到 51 个文件\n",
      "2026-01-23 18:17:37,564 - INFO - [完成] 16.第十六节 房地产投资手册 (3文件)\n",
      "2026-01-23 18:17:37,564 - INFO - [完成] 14.第十四节 汇率投资手册 (3文件)\n",
      "2026-01-23 18:17:37,564 - INFO - [完成] 02第二节 消费——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:17:37,565 - INFO - [完成] 04第四节 出口——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:17:37,565 - INFO - [完成] 13.第十三节 黄金投资手册 (3文件)\n",
      "2026-01-23 18:17:37,566 - INFO - [完成] 10第十节 股市投资手册 (3文件)\n",
      "2026-01-23 18:17:37,566 - INFO - [完成] 09第九节 看懂投资时钟，踩准投资节奏 (3文件)\n",
      "2026-01-23 18:17:37,566 - INFO - [完成] 17.第十七节 格雷厄姆：华尔街教父 (3文件)\n",
      "2026-01-23 18:17:37,567 - INFO - [完成] 01第一节 中国经济的“三驾马车” (3文件)\n",
      "2026-01-23 18:17:37,567 - INFO - [完成] 15.第十五节 大宗商品投资手册 (3文件)\n",
      "2026-01-23 18:17:37,567 - INFO - [完成] 12.第十二节 保险投资手册 (3文件)\n",
      "2026-01-23 18:17:37,568 - INFO - [完成] 05第五节 PMI——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:17:37,568 - INFO - [完成] 07第七节 物价——快速入门读懂经 (3文件)\n",
      "2026-01-23 18:17:37,568 - INFO - [完成] 03第三节 投资——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:17:37,569 - INFO - [完成] 08第八节 如何读懂经济周期_222945 (3文件)\n",
      "2026-01-23 18:17:37,569 - INFO - [完成] 11.第十一节 基金投资手册 (3文件)\n",
      "2026-01-23 18:17:37,569 - INFO - [完成] 06第六节 金融——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:17:37,569 - INFO - [完成] 17 个知识块\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始完整Pipeline，领域: macro_economy\n",
      "================================================================================\n",
      "\n",
      "领域: macro_economy (共2个知识块)\n",
      "--------------------------------------------------------------------------------\n",
      "[进度] 1/2 01第一节 中国经济的“三驾马车”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:17:38,310 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:17:38,346 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:17:59,741 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666]_20250706193405.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:17:59,752 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 01_01第一节 中国经济的“三驾马车”.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 2/2 02第二节 消费——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:05,881 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:05,885 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:05,923 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666]_20250707140225.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:05,924 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 02_02第二节 消费——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 7 chunks\n",
      "\n",
      "达到限制(2)，停止\n",
      "\n",
      "[完成] macro_economy: 2/2 个\n",
      "================================================================================\n",
      "[完成] Pipeline执行完成\n",
      "================================================================================\n",
      "\n",
      "输出目录:\n",
      "  - JSON: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/structured/macro_economy\n",
      "  - 向量库: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/vector_db/macro_economy\n"
     ]
    }
   ],
   "source": [
    "# 测试: 处理前2个知识块\n",
    "processor.process_all(limit=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:08,147 - INFO - 扫描目录: /Users/Qunying/Project/python/AnalystChain/data/raw/knowledge_base/macro_economy\n",
      "2026-01-23 18:18:08,149 - INFO - 找到 51 个文件\n",
      "2026-01-23 18:18:08,150 - INFO - [完成] 16.第十六节 房地产投资手册 (3文件)\n",
      "2026-01-23 18:18:08,151 - INFO - [完成] 14.第十四节 汇率投资手册 (3文件)\n",
      "2026-01-23 18:18:08,151 - INFO - [完成] 02第二节 消费——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:18:08,152 - INFO - [完成] 04第四节 出口——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:18:08,152 - INFO - [完成] 13.第十三节 黄金投资手册 (3文件)\n",
      "2026-01-23 18:18:08,153 - INFO - [完成] 10第十节 股市投资手册 (3文件)\n",
      "2026-01-23 18:18:08,153 - INFO - [完成] 09第九节 看懂投资时钟，踩准投资节奏 (3文件)\n",
      "2026-01-23 18:18:08,153 - INFO - [完成] 17.第十七节 格雷厄姆：华尔街教父 (3文件)\n",
      "2026-01-23 18:18:08,154 - INFO - [完成] 01第一节 中国经济的“三驾马车” (3文件)\n",
      "2026-01-23 18:18:08,154 - INFO - [完成] 15.第十五节 大宗商品投资手册 (3文件)\n",
      "2026-01-23 18:18:08,154 - INFO - [完成] 12.第十二节 保险投资手册 (3文件)\n",
      "2026-01-23 18:18:08,155 - INFO - [完成] 05第五节 PMI——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:18:08,155 - INFO - [完成] 07第七节 物价——快速入门读懂经 (3文件)\n",
      "2026-01-23 18:18:08,155 - INFO - [完成] 03第三节 投资——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:18:08,156 - INFO - [完成] 08第八节 如何读懂经济周期_222945 (3文件)\n",
      "2026-01-23 18:18:08,156 - INFO - [完成] 11.第十一节 基金投资手册 (3文件)\n",
      "2026-01-23 18:18:08,156 - INFO - [完成] 06第六节 金融——快速入门读懂经济形势 (3文件)\n",
      "2026-01-23 18:18:08,156 - INFO - [完成] 17 个知识块\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始完整Pipeline，领域: macro_economy\n",
      "================================================================================\n",
      "\n",
      "领域: macro_economy (共17个知识块)\n",
      "--------------------------------------------------------------------------------\n",
      "[进度] 1/17 01第一节 中国经济的“三驾马车”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:08,177 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:08,180 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:08,214 - INFO - 加载 01第一节 中国经济的“三驾马车”[防断更微coc36666]_20250706193405.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:08,216 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 01_01第一节 中国经济的“三驾马车”.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 2/17 02第二节 消费——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:10,058 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:10,061 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:10,096 - INFO - 加载 02第二节 消费——快速入门读懂经济形势[防断更微coc36666]_20250707140225.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:10,098 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 02_02第二节 消费——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 7 chunks\n",
      "[进度] 3/17 03第三节 投资——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:11,683 - INFO - 加载 03第三节 投资——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:11,686 - INFO - 加载 03第三节 投资——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:11,725 - INFO - 加载 03第三节 投资——快速入门读懂经济形势[防断更微coc36666]_20250707140243.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:11,727 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 03_03第三节 投资——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 4/17 04第四节 出口——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:14,457 - INFO - 加载 04第四节 出口——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:14,460 - INFO - 加载 04第四节 出口——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:14,494 - INFO - 加载 04第四节 出口——快速入门读懂经济形势[防断更微coc36666]_20250707140251.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:14,496 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 04_04第四节 出口——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 6 chunks\n",
      "[进度] 5/17 05第五节 PMI——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:16,222 - INFO - 加载 05第五节 PMI——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：5页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:16,225 - INFO - 加载 05第五节 PMI——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:16,252 - INFO - 加载 05第五节 PMI——快速入门读懂经济形势[防断更微coc36666]_20251130222243.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 7 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:16,254 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 05_05第五节 PMI——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 6/17 06第六节 金融——快速入门读懂经济形势\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:18,880 - INFO - 加载 06第六节 金融——快速入门读懂经济形势[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:18,883 - INFO - 加载 06第六节 金融——快速入门读懂经济形势[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:18,913 - INFO - 加载 06第六节 金融——快速入门读懂经济形势[防断更微coc36666]_20251130222414.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:18,914 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 06_06第六节 金融——快速入门读懂经济形势.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 7/17 07第七节 物价——快速入门读懂经\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:21,340 - INFO - 加载 07第七节 物价——快速入门读懂经[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:21,343 - INFO - 加载 07第七节 物价——快速入门读懂经[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:21,375 - INFO - 加载 07第七节 物价——快速入门读懂经[防断更微coc36666]_20251130222700.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:21,377 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 07_07第七节 物价——快速入门读懂经.json\n",
      "[进度] 向量化: 7 chunks\n",
      "[进度] 8/17 08第八节 如何读懂经济周期_222945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:23,512 - INFO - 加载 08第八节 如何读懂经济周期[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:23,515 - INFO - 加载 08第八节 如何读懂经济周期[防断更微coc36666]_20251130_222945.doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:23,539 - INFO - 加载 08第八节 如何读懂经济周期[防断更微coc36666]_20251130222832.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:23,541 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 08_08第八节 如何读懂经济周期_222945.json\n",
      "[进度] 向量化: 7 chunks\n",
      "[进度] 9/17 09第九节 看懂投资时钟，踩准投资节奏\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:25,286 - INFO - 加载 09第九节 看懂投资时钟，踩准投资节奏[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:25,290 - INFO - 加载 09第九节 看懂投资时钟，踩准投资节奏[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:25,349 - INFO - 加载 09第九节 看懂投资时钟，踩准投资节奏[防断更微coc36666]_20251130223006.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:25,351 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 09_09第九节 看懂投资时钟，踩准投资节奏.json\n",
      "[进度] 向量化: 11 chunks\n",
      "[进度] 10/17 10第十节 股市投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:28,703 - INFO - 加载 10第十节 股市投资手册[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:28,706 - INFO - 加载 10第十节 股市投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:28,733 - INFO - 加载 10第十节 股市投资手册[防断更微coc36666]_20251130223842.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:28,736 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 10_10第十节 股市投资手册.json\n",
      "[进度] 向量化: 9 chunks\n",
      "[进度] 11/17 11.第十一节 基金投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:31,265 - INFO - 加载 11.第十一节 基金投资手册[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:31,267 - INFO - 加载 11.第十一节 基金投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:31,290 - INFO - 加载 11.第十一节 基金投资手册[防断更微coc36666]_20251130223902.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:31,291 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 11_11.第十一节 基金投资手册.json\n",
      "[进度] 向量化: 7 chunks\n",
      "[进度] 12/17 12.第十二节 保险投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:32,990 - INFO - 加载 12.第十二节 保险投资手册[防断更微coc36666]_笔记.pdf：5页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:32,993 - INFO - 加载 12.第十二节 保险投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:33,016 - INFO - 加载 12.第十二节 保险投资手册[防断更微coc36666]_20251130223935.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 7 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:33,017 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 12_12.第十二节 保险投资手册.json\n",
      "[进度] 向量化: 8 chunks\n",
      "[进度] 13/17 13.第十三节 黄金投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:35,334 - INFO - 加载 13.第十三节 黄金投资手册[防断更微coc36666]_笔记.pdf：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:35,337 - INFO - 加载 13.第十三节 黄金投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:35,362 - INFO - 加载 13.第十三节 黄金投资手册[防断更微coc36666]_20251130224009.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:35,363 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 13_13.第十三节 黄金投资手册.json\n",
      "[进度] 向量化: 5 chunks\n",
      "[进度] 14/17 14.第十四节 汇率投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:36,859 - INFO - 加载 14.第十四节 汇率投资手册[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:36,861 - INFO - 加载 14.第十四节 汇率投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:36,882 - INFO - 加载 14.第十四节 汇率投资手册[防断更微coc36666]_20251130224038.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:36,884 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 14_14.第十四节 汇率投资手册.json\n",
      "[进度] 向量化: 6 chunks\n",
      "[进度] 15/17 15.第十五节 大宗商品投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:38,708 - INFO - 加载 15.第十五节 大宗商品投资手册[防断更微coc36666]_笔记.pdf：4页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 4 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:38,710 - INFO - 加载 15.第十五节 大宗商品投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:38,740 - INFO - 加载 15.第十五节 大宗商品投资手册[防断更微coc36666]_20251130224057.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 6 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:38,742 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 15_15.第十五节 大宗商品投资手册.json\n",
      "[进度] 向量化: 9 chunks\n",
      "[进度] 16/17 16.第十六节 房地产投资手册\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:41,144 - INFO - 加载 16.第十六节 房地产投资手册[防断更微coc36666]_笔记.pdf：5页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:41,147 - INFO - 加载 16.第十六节 房地产投资手册[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:41,187 - INFO - 加载 16.第十六节 房地产投资手册[防断更微coc36666]_20251130224121.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 7 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:41,189 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 16_16.第十六节 房地产投资手册.json\n",
      "[进度] 向量化: 11 chunks\n",
      "[进度] 17/17 17.第十七节 格雷厄姆：华尔街教父\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:43,776 - INFO - 加载 17.第十七节 格雷厄姆：华尔街教父[防断更微coc36666]_笔记.pdf：3页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pdf: 3 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:43,779 - INFO - 加载 17.第十七节 格雷厄姆：华尔街教父[防断更微coc36666].doc：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .doc: 1 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:43,794 - INFO - 加载 17.第十七节 格雷厄姆：华尔街教父[防断更微coc36666]_20251130224150.pptx：1页\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] 加载 .pptx: 1 页\n",
      "[进度] 总计: 5 页\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 18:18:43,796 - WARNING - [KnowledgeExtractor] LLM提取失败: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n  \"topic\"\\'}.  Expected: [\\'\\\\n  \"topic\"\\', \\'content\\'] Received: [\\'content\\']\\nNote: if you intended {\\n  \"topic\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n  \"topic\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[进度] JSON: 17_17.第十七节 格雷厄姆：华尔街教父.json\n",
      "[进度] 向量化: 5 chunks\n",
      "\n",
      "[完成] macro_economy: 17/17 个\n",
      "================================================================================\n",
      "[完成] Pipeline执行完成\n",
      "================================================================================\n",
      "\n",
      "输出目录:\n",
      "  - JSON: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/structured/macro_economy\n",
      "  - 向量库: /Users/Qunying/Project/python/AnalystChain/data/processed/knowledge/vector_db/macro_economy\n"
     ]
    }
   ],
   "source": [
    "# 正式运行：处理所有知识块（取消注释）\n",
    "processor.process_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出结构\n",
    "\n",
    "### JSON结构\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"topic\": \"主题名称\",\n",
    "  \"key_concepts\": [\n",
    "    {\"name\": \"概念名\", \"definition\": \"定义\", \"importance\": \"重要性\"}\n",
    "  ],\n",
    "  \"indicators\": [\n",
    "    {\"name\": \"指标名\", \"calculation\": \"计算方法\", \"interpretation\": \"解读\"}\n",
    "  ],\n",
    "  \"analysis_methods\": [\n",
    "    {\"name\": \"方法名\", \"steps\": \"步骤\", \"application\": \"应用\"}\n",
    "  ],\n",
    "  \"summary\": \"总结\"\n",
    "}\n",
    "```\n",
    "\n",
    "**存储位置**：`data/processed/knowledge/structured/{domain}/*.json`\n",
    "\n",
    "### 向量库结构\n",
    "\n",
    "**存储位置**：`data/processed/knowledge/vector_db/{domain}/`\n",
    "\n",
    "**内容**：\n",
    "- 文档分块（chunk_size=800，overlap=100）\n",
    "- 向量化（Qwen3-Embedding）\n",
    "- 元数据（domain、topic、sequence）\n",
    "\n",
    "**使用方式**：通过Chroma向量库进行语义检索\n",
    "\n",
    "### 使用示例\n",
    "\n",
    "**读取JSON**：\n",
    "```python\n",
    "import json\n",
    "with open(\"data/processed/knowledge/structured/macro_economy/01_01第一节.json\", \"r\") as f:\n",
    "    knowledge = json.load(f)\n",
    "    print(knowledge[\"topic\"])  # 主题名称\n",
    "    print(knowledge[\"key_concepts\"][0][\"name\"])  # 第一个概念\n",
    "```\n",
    "\n",
    "**向量检索**：\n",
    "```python\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "vector_store = Chroma(persist_directory=\"data/processed/knowledge/vector_db/macro_economy\",\n",
    "                     embedding_function=embeddings)\n",
    "results = vector_store.similarity_search(\"经济周期\", k=3)\n",
    "```\n",
    "\n",
    "## 快速参考\n",
    "\n",
    "**核心流程**：扫描分组 → 加载清洗 → LLM提取 → 向量化 → 协调执行\n",
    "\n",
    "**输出位置**：\n",
    "- JSON: `data/processed/knowledge/structured/{domain}/*.json`\n",
    "- 向量库: `data/processed/knowledge/vector_db/{domain}/`\n",
    "\n",
    "**使用步骤**：\n",
    "1. `limit=2` 测试\n",
    "2. `process_all()` 处理全部\n",
    "3. 检查输出结果\n",
    "\n",
    "**注意事项**：首次运行会自动下载embedding模型\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyst_chain (conda)",
   "language": "python",
   "name": "analyst_chain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
