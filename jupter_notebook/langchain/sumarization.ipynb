{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3994f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../config/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901d702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264fe40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf60c6f",
   "metadata": {},
   "source": [
    "### 通过一次大模型调用总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84b1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这篇博客文章《LLM Powered Autonomous Agents》由Lilian Weng撰写，系统地概述了如何利用大型语言模型（LLM）作为核心控制器来构建自主智能体系统。文章将这类系统分解为三个核心组件，并结合实际案例和挑战进行了深入探讨。\n",
      "\n",
      "### 核心摘要：\n",
      "\n",
      "**1. 代理系统概述**\n",
      "一个LLM驱动的自主代理系统以LLM作为“大脑”，并辅以三个关键组件：\n",
      "- **规划**：将复杂任务分解为子目标，并进行自我反思以改进策略。\n",
      "- **记忆**：包括短期记忆（利用模型的上下文学习能力）和长期记忆（通过外部向量存储实现信息的持久化和快速检索）。\n",
      "- **工具使用**：学习调用外部API来获取模型权重中缺失的信息（如实时数据、代码执行能力）。\n",
      "\n",
      "**2. 核心组件详解**\n",
      "\n",
      "- **规划**\n",
      "    - **任务分解**：通过思维链、思维树等提示技术，或将规划外包给经典规划器（如LLM+P），将大任务拆解为小步骤。\n",
      "    - **自我反思**：通过ReAct、Reflexion、Chain of Hindsight和Algorithm Distillation等框架，使代理能够从过去的错误中学习，迭代改进其输出和策略。\n",
      "\n",
      "- **记忆**\n",
      "    - **类型**：类比人类记忆，分为感觉记忆（嵌入表示）、短期记忆（上下文学习）和长期记忆（外部向量存储）。\n",
      "    - **检索**：使用近似最近邻算法（如HNSW, FAISS, ScaNN）进行快速最大内积搜索，以实现高效的内存检索。\n",
      "\n",
      "- **工具使用**\n",
      "    - 代理通过学习调用外部工具（如计算器、搜索引擎、API）来扩展其能力。\n",
      "    - 相关框架包括MRKL、TALM、Toolformer，以及实践中的ChatGPT插件和OpenAI函数调用。\n",
      "    - **HuggingGPT** 和 **API-Bank** 是 benchmarks 和框架，展示了LLM如何作为任务规划器，协调和利用外部模型与工具。\n",
      "\n",
      "**3. 案例研究**\n",
      "\n",
      "- **科学发现代理**：如ChemCrow，通过集成13个专家设计的工具，在化学合成等领域完成任务。研究表明，尽管LLM自我评估可能相近，但专家评估显示工具增强的代理表现更优。\n",
      "- **生成式代理模拟**：在一个沙盒环境中模拟25个由LLM驱动的虚拟角色的生活，通过记忆、规划和反思机制，产生了信息传播、关系记忆等涌现社会行为。\n",
      "- **概念验证示例**：如AutoGPT和GPT-Engineer，展示了LLM作为自主代理控制器的潜力，尽管存在可靠性问题，但仍是重要的概念验证。\n",
      "\n",
      "**4. 挑战**\n",
      "- **有限的上下文长度**：限制了历史信息、详细指令和响应的容纳。\n",
      "- **长期规划与任务分解的困难**：LLM在面临意外错误时调整计划的能力较弱。\n",
      "- **自然语言接口的可靠性**：模型输出可能存在格式错误或拒绝遵循指令的情况，导致系统需要大量代码进行输出解析。\n",
      "\n",
      "### 结论：\n",
      "LLM驱动的自主代理是一个充满前景且快速发展的领域。通过整合规划、记忆和工具使用，这些代理能够处理复杂任务。然而，在可靠性、长期规划和上下文处理方面仍面临挑战，需要在未来研究中加以解决。"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"请对以下内容写一个简明的总结：\\\\n\\\\n{context}\")]\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "for token in chain.invoke({\"context\": docs}):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c79d5d",
   "metadata": {},
   "source": [
    "### 通过Map-Reduce架构并行化总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89cfe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6967dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain.chains.combine_documents.reduce import (\n",
    "    acollapse_docs,\n",
    "    split_list_of_docs,\n",
    ")\n",
    "\n",
    "# 单次处理的最大token数量\n",
    "token_max = 1000\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"写下以下内容的简明摘要：{context}\")]\n",
    ")\n",
    "\n",
    "reduce_template = \"\"\"\n",
    "以下是一组摘要：\n",
    "{docs}\n",
    "请将这些内容提炼成一个最终的、综合的摘要，概括主要主题。\n",
    "\"\"\"\n",
    "reduce_prompt = ChatPromptTemplate(\n",
    "    [(\"human\", reduce_template)]\n",
    ")\n",
    "\n",
    "# 主图状态：管理整个摘要流程的数据流\n",
    "class OverallState(TypedDict):\n",
    "    contents: List[str]\n",
    "    summaries: Annotated[list, operator.add]\n",
    "    collapsed_summaries: List[Document]\n",
    "    final_summary: str\n",
    "\n",
    "class SummaryState(TypedDict):\n",
    "    content: str\n",
    "\n",
    "# 计算文档列表的总token数量\n",
    "def length_function(documents: List[Document]) -> int:\n",
    "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)\n",
    "\n",
    "# 为每个文档内容创建一个Send对象，实现并行处理\n",
    "def map_summaries(state: OverallState):\n",
    "    return [\n",
    "        Send(\"generate_summary\", {\"content\": content}) for content in state[\"contents\"]\n",
    "    ]\n",
    "\n",
    "# 将多个摘要合并成一个\n",
    "async def _reduce(input: dict) -> str:\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# 判断是否需要继续合并摘要\n",
    "def should_collapse(state: OverallState):\n",
    "    num_tokens = length_function(state[\"collapsed_summaries\"])\n",
    "\n",
    "    if num_tokens > token_max:\n",
    "        return \"collapse_summaries\"\n",
    "    else:\n",
    "        return \"generate_final_summary\"\n",
    "\n",
    "# 为单个文档生成摘要（Map阶段的核心函数）\n",
    "async def generate_summary(state: SummaryState):\n",
    "    prompt = map_prompt.invoke(state[\"content\"])\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return {\"summaries\": [response.content]}\n",
    "\n",
    "# 收集摘要：将并行生成的摘要收集成文档列表\n",
    "def collect_summaries(state: OverallState):\n",
    "    return {\"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]}\n",
    "\n",
    "# 智能合并摘要：根据token限制分批合并摘要\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    doc_lists = split_list_of_docs(\n",
    "        state[\"collapsed_summaries\"],\n",
    "        length_function,\n",
    "        token_max,\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for doc_list in doc_lists:\n",
    "        results.append(await acollapse_docs(doc_list, _reduce))\n",
    "\n",
    "    return {\"collapsed_summaries\": results}\n",
    "\n",
    "# 生成最终摘要结果\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\": response}\n",
    "\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\", generate_summary)\n",
    "graph.add_node(\"collect_summaries\", collect_summaries)\n",
    "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
    "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
    "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
    "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
    "graph.add_edge(\"generate_final_summary\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89eb115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['collect_summaries']\n",
      "['collapse_summaries']\n",
      "['collapse_summaries']\n",
      "['collapse_summaries']\n",
      "['collapse_summaries']\n",
      "['collapse_summaries']\n",
      "['generate_final_summary']\n",
      "基于大型语言模型（LLM）的人工智能代理系统通过整合**规划、记忆和工具使用**三大核心能力，结合推理与行动（ReAct框架）及自我反思机制，实现了复杂任务的自主执行与持续改进，被视为迈向通用人工智能（AGI）的重要进展。\n",
      "\n",
      "当前发展聚焦两大方向：\n",
      "1. **增强通用模型能力**：通过集成外部工具（如API、专家模型）突破LLM固有限制，实现复杂任务自动化与专业应用，同时面临参数提取、安全风险等挑战；\n",
      "2. **赋能专业开发流程**：通过AI驱动的代码开发工具集、结构化需求澄清和代码质量标准，系统化提升软件开发效率。\n",
      "\n",
      "技术瓶颈主要体现在：\n",
      "- 上下文窗口限制导致扩展困难\n",
      "- 长期任务规划与错误恢复的稳健性不足\n",
      "- 自然语言接口可靠性问题（格式错误、指令拒绝等）\n",
      "- 对代码生成质量的高标准要求（需完整可执行且符合架构规范）\n",
      "\n",
      "总体而言，LLM智能体在展现强大问题解决能力的同时，仍需在上下文处理、规划稳健性和接口可靠性等关键技术环节实现突破。\n"
     ]
    }
   ],
   "source": [
    "async for step in app.astream(\n",
    "    {\"contents\": [doc.page_content for doc in split_docs]},\n",
    "    {\"recursion_limit\": 10},\n",
    "):\n",
    "    print(list(step.keys()))\n",
    "    if \"generate_final_summary\" in step:\n",
    "        print(step[\"generate_final_summary\"][\"final_summary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyst_chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
